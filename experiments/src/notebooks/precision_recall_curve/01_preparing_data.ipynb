{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import boto3\n",
    "from eliot import log_message\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.engine.url import URL\n",
    "from sqlalchemy import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DbEngine(object):\n",
    "    \"\"\"\n",
    "    Fetch the credentials from AWS Secrets Manager.\n",
    "    :return: DB connection to the respective database\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, region_name='us-east-1'):\n",
    "        self.session = boto3.session.Session()\n",
    "        self.secrets_client = self.session.client(\n",
    "            service_name='secretsmanager',\n",
    "            region_name=region_name\n",
    "        )\n",
    "\n",
    "    def get_secrets(self, secret_name):\n",
    "        \"\"\"\n",
    "        :return: Based on the environment get secrets for\n",
    "        Client SQL db & Postgres Saivadb\n",
    "        \"\"\"\n",
    "        log_message(message_type='info', action_type='get_secrets', secret_name=secret_name)\n",
    "        db_info = json.loads(\n",
    "            self.secrets_client.get_secret_value(SecretId=secret_name)[\n",
    "                'SecretString'\n",
    "            ]\n",
    "        )\n",
    "        return db_info\n",
    "\n",
    "    def get_postgresdb_engine(self):\n",
    "        \"\"\"\n",
    "        Based on the environment connects to the respective database\n",
    "        :param client: client name\n",
    "        :return: Saivadb Postgres engine\n",
    "        \"\"\"\n",
    "        log_message(message_type='info', action_type='connect_to_postgresdb', client='SaivaDB')\n",
    "        # Fetch credentials from AWS Secrets Manager\n",
    "        postgresdb_info = self.get_secrets(secret_name=f'prod-saivadb')\n",
    "        # Create DB URL\n",
    "        saivadb_url = URL(\n",
    "            drivername='postgresql',\n",
    "            username=postgresdb_info['username'],\n",
    "            password=postgresdb_info['password'],\n",
    "            host=postgresdb_info['host'],\n",
    "            port=postgresdb_info['port'],\n",
    "            database=postgresdb_info['dbname'],\n",
    "        )\n",
    "        # Return Postgres Engine\n",
    "        return create_engine(saivadb_url, echo=False)\n",
    "    \n",
    "    def get_sqldb_engine(self, clientdb_name):\n",
    "        \"\"\"\n",
    "        Based on the environment connects to the respective database.\n",
    "        Avante db is in client VPN hence we use different credentials.\n",
    "        :param client: client name\n",
    "        :return: Client SQL engine\n",
    "        \"\"\"\n",
    "        log_message(message_type='info', action_type='connect_to_sqldb', client=clientdb_name)\n",
    "        # Fetch credentials from AWS Secrets Manager\n",
    "        if clientdb_name == 'avante':\n",
    "            sqldb_info = self.get_secrets(secret_name=f'avantedb')\n",
    "        else:\n",
    "            sqldb_info = self.get_secrets(secret_name=f'prod-sqlserver')\n",
    "            sqldb_info['dbname'] = clientdb_name\n",
    "\n",
    "        # Create DB URL\n",
    "        client_sqldb_url = URL(\n",
    "            drivername='mssql+pyodbc',\n",
    "            username=sqldb_info['username'],\n",
    "            password=sqldb_info['password'],\n",
    "            host=sqldb_info['host'],\n",
    "            port=sqldb_info['port'],\n",
    "            database=sqldb_info['dbname'],\n",
    "            query={'driver': 'ODBC Driver 17 for SQL Server'},\n",
    "        )\n",
    "        # Return Sql Engine\n",
    "        return create_engine(client_sqldb_url, echo=False)\n",
    "    \n",
    "    def verify_connectivity(self, engine):\n",
    "        assert engine.execute('select 1').fetchall() is not None  # verify connectivity\n",
    "\n",
    "engine = DbEngine()\n",
    "client_engine =  engine.get_postgresdb_engine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "with rh as (\n",
    "    select ht.*,\n",
    "    fa.facilityname,\n",
    "    fp.masterpatientid,\n",
    "    dp.modelid,\n",
    "    dp.predictionrank,\n",
    "    dp.censusdate,\n",
    "    dp.show_in_report,\n",
    "    fp.patientmrn,\n",
    "    fp.firstname,\n",
    "    fp.lastname\n",
    "    from public.hospital_transfers ht\n",
    "        left join public.facility_patient fp\n",
    "        on ht.client = fp.client\n",
    "        and ht.facilityid = fp.facilityid\n",
    "        and ht.patientid = fp.patientid\n",
    "            left join daily_predictions dp\n",
    "            on ht.client = dp.client\n",
    "            and ht.facilityid = dp.facilityid\n",
    "            and (date(ht.dateoftransfer) - date(dp.censusdate)) <= 3\n",
    "            and (date(ht.dateoftransfer) - date(dp.censusdate)) != 0\n",
    "            and date(dp.censusdate) <= date(ht.dateoftransfer)\n",
    "            and fp.masterpatientid = dp.masterpatientid\n",
    "            left join facility fa\n",
    "            on fa.facilityid = ht.facilityid\n",
    "            and fa.client = ht.client\n",
    "    where (dp.published = True or dp.published is null)\n",
    "      and ht.dateoftransfer >= '2020-01-01 00:00:00'\n",
    "      and (dp.experiment_group = True or dp.experiment_group is null)\n",
    "      and fa.is_active=true\n",
    "      and ht.planned='No'\n",
    "      and (ht.outcome !='ED Visit Only' or ht.outcome is null)\n",
    "      and (lower(ht.payerdescription) NOT LIKE '%hospice%' \n",
    "      or ht.payerdescription is null)\n",
    "\n",
    ")\n",
    "    SELECT rh.client,\n",
    "           rh.facilityid,\n",
    "           rh.facilityname,\n",
    "           rh.modelid,\n",
    "           rh.patientid,\n",
    "           rh.masterpatientid,\n",
    "           rh.patientmrn,\n",
    "           rh.lastname,\n",
    "           rh.firstname,\n",
    "           rh.censusdate,\n",
    "           rh.dateoftransfer,\n",
    "           rh.lastadmissiondate,\n",
    "           rh.planned,\n",
    "           rh.transferreason,\n",
    "           rh.otherreasonfortransfer,\n",
    "           rh.outcome,\n",
    "           rh.transferredto,\n",
    "           rh.lengthofstay,\n",
    "           rh.payertype,\n",
    "           rh.payerdescription,\n",
    "           rh.predictionrank as rank_cutoff,\n",
    "           bool_or(rh.show_in_report) as show_in_report,\n",
    "           (CASE\n",
    "                WHEN bool_or(rh.show_in_report) IS NULL\n",
    "                    THEN 0\n",
    "                ELSE count(*)\n",
    "               END\n",
    "               ) as num_predictions\n",
    "    FROM rh\n",
    "    GROUP BY rh.client, rh.facilityid, rh.facilityname, rh.modelid,\n",
    "             rh.patientid, rh.masterpatientid, rh.patientmrn, rh.lastname, rh.firstname, rh.censusdate, rh.dateoftransfer, \n",
    "             rh.lastadmissiondate, rh.planned, rh.transferreason, rh.otherreasonfortransfer, rh.outcome,\n",
    "             rh.transferredto, rh.lengthofstay, rh.payertype, rh.payerdescription,rh.predictionrank\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = pd.read_sql(text(query), con = client_engine)\n",
    "base_df\n",
    "# dataframe contains all the transferred residents.\n",
    "base_df['resident_transferred'] = 1\n",
    "base_df = base_df.sort_values(by=['client', 'facilityid', 'facilityname', 'masterpatientid', 'censusdate', 'dateoftransfer', 'rank_cutoff'])\n",
    "base_df.to_csv('RTH_data.csv', index=False)\n",
    "base_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "select date(censusdate) as censusdate, client,facilityid ,count(*) as ranked_d from daily_predictions dp\n",
    "group by censusdate,client,facilityid\n",
    "\n",
    "\"\"\"\n",
    "ranked_d = pd.read_sql(query, con = client_engine)\n",
    "ranked_d.to_csv('ranked_d.csv', index=False)\n",
    "ranked_d.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
