{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import pickle\n",
    "from saiva.training.data_models import BaseModel\n",
    "from saiva.model.shared.load_raw_data import join_tables\n",
    "from saiva.model.explanations import DataProcessor, get_config_value\n",
    "from pathlib import Path\n",
    "import boto3\n",
    "from urllib.parse import urlparse\n",
    "import pandas as pd\n",
    "\n",
    "import shap\n",
    "import re\n",
    "from saiva.model.shared.explanations_config import exp_dictionary # TODO: module does not exist\n",
    "from saiva.model.shared.explanations_config import FEATURE_GROUP_MAPPING, FEATURE_TYPE_MAPPING # TODO: module does not exist\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_date = '2021-02-02'\n",
    "client = 'avante'\n",
    "facilityid = '1'\n",
    "s3_path = f's3://saiva-dev-data-bucket/unit_test_data/explanations/{client}/{prediction_date}'\n",
    "modelid = 'd0c497c8b9b04f4d9e1e1e0c9297cc1f'\n",
    "\n",
    "table_list = ['master_patient_lookup', 'patient_census', 'patient_rehosps','patient_room_details',\n",
    "              'patient_progress_notes', 'patient_diagnosis', 'patient_vitals', 'patient_lab_results',\n",
    "              'patient_meds', 'patient_orders', 'patient_alerts', 'patient_demographics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading master_patient_lookup\n",
      "reading patient_census\n",
      "reading patient_rehosps\n",
      "reading patient_room_details\n",
      "reading patient_progress_notes\n",
      "reading patient_diagnosis\n",
      "reading patient_vitals\n",
      "reading patient_lab_results\n",
      "reading patient_meds\n",
      "reading patient_orders\n",
      "reading patient_alerts\n",
      "reading patient_demographics\n"
     ]
    }
   ],
   "source": [
    "raw_data_dict = {}\n",
    "for table in table_list:\n",
    "    print(f\"reading {table}\")\n",
    "    raw_data_dict[table] = pd.read_parquet(\n",
    "        f\"{s3_path}/{table}.parquet\"\n",
    "    )\n",
    "\n",
    "with open(f\"/data/models/{modelid}/artifacts/{modelid}.pickle\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "final_x = pd.read_parquet(f\"{s3_path}/pd_final_df.parquet\")\n",
    "final_idens = pd.read_parquet(f\"{s3_path}/pd_final_idens.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ret_dict = process_raw_data(raw_data_dict)\n",
    "    \n",
    "explainer = shap.TreeExplainer(model.model)\n",
    "shap_values = explainer.shap_values(final_x)\n",
    "\n",
    "shap_results = []\n",
    "\n",
    "for idx, row in final_x.iterrows():\n",
    "    shaps = pd.DataFrame(\n",
    "        {\n",
    "            \"feature\": final_x.columns,\n",
    "            \"attribution_score\": shap_values[1][idx],\n",
    "            \"feature_value\": final_x.iloc[idx],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    shaps[\"masterpatientid\"] = final_idens.iloc[idx].masterpatientid\n",
    "    shaps[\"facilityid\"] = final_idens.iloc[idx].facilityid\n",
    "    shaps[\"censusdate\"] = final_idens.iloc[idx].censusdate\n",
    "    shaps['human_readable_name'] = ''\n",
    "    shaps['mapping_status'] = 'NOT_MAPPED'\n",
    "    \n",
    "    shap_results.append(shaps)\n",
    "\n",
    "\n",
    "results = pd.concat(shap_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results['mapped_feature'] = results['feature'].replace(\n",
    "        FEATURE_GROUP_MAPPING,\n",
    "        regex=True\n",
    "    )\n",
    "results['feature_type'] = results['feature'].replace(\n",
    "    FEATURE_TYPE_MAPPING,\n",
    "    regex=True\n",
    ")\n",
    "results['day_count'] = results['feature'].str.extract(r'_(\\d+)_day')\n",
    "results['day_count'] = results['day_count'].fillna(\"100\").astype(int)\n",
    "results['all_time'] = results['feature'].str.extract(r'_(all)_')\n",
    "\n",
    "condition = (results.mapped_feature.str.startswith(('cumsum_alert_','cumsum_med_','cumsum_labs_','cumsum_order_','cumsum_order_','cumsum_dx_'))) & (results.feature_value == 0) \n",
    "results.loc[condition,'mapping_status'] = 'NOT_RELEVANT'\n",
    "\n",
    "# Calculate Avg attribution_score for all rows\n",
    "_df = results.groupby(['masterpatientid', 'facilityid', 'mapped_feature']\n",
    "                      )['attribution_score'].mean().reset_index()\n",
    "_df = _df.rename(columns={'attribution_score': 'sum_attribution_score'})\n",
    "results = results.merge(_df, how='left', on=['masterpatientid', 'facilityid', 'mapped_feature'])\n",
    "\n",
    "\"\"\" Remove duplicate feature columns.\n",
    "ie. cumsum columns have 7, 14, 30 & ALL day variants.\n",
    "Use the most recent variant ie. sort by day_count and pick the first row\n",
    "\"\"\"\n",
    "\n",
    "results.sort_values(by=['day_count'], inplace=True, ascending=True)\n",
    "results = results.drop_duplicates(\n",
    "    subset=['masterpatientid', 'facilityid', 'mapped_feature'],\n",
    "    keep='first'\n",
    ")\n",
    "\n",
    "results['censusdate'] = pd.to_datetime(results.censusdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This pattern has match groups. To actually get the groups, use str.extract.\n"
     ]
    }
   ],
   "source": [
    "dp = DataProcessor(raw_data_dict)\n",
    "raw_data = dp.fetch_processed_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dx_mapper(dx_attribution, diag_data, mpid_to_use, date_to_use, diagnosis_explanation_config):\n",
    "    print('+++++++++++++++++++++++++++++++++0')\n",
    "    diag_label = dx_attribution['mapped_feature'].replace('cumsum_dx_', '')\n",
    "\n",
    "    diag_matches = diag_data[(diag_data.masterpatientid == mpid_to_use) &\n",
    "                             (diag_data.ccs_label == diag_label)]\n",
    "    day_count = dx_attribution['day_count']\n",
    "    diag_reason = filter_date_range(\n",
    "        day_count,\n",
    "        diag_matches,\n",
    "        diag_matches.onsetdate,\n",
    "        date_to_use\n",
    "    )\n",
    "    print('+++++++++++++++++++++++++++++++++1')\n",
    "    if (len(diag_reason) > 0):\n",
    "        # do not show onsetdate for patients whose initialadmissiondate equals onsetdate.\n",
    "        # patients set diagnosis onsetdate as initialadmissiondate when they're unaware of the real onsetdate.\n",
    "        if diag_reason.iloc[0]['onsetdate'] != diag_reason.iloc[0]['initialadmissiondate']:\n",
    "            human_readable_name = f\"Diagnosis of {diag_reason.iloc[0]['diagnosiscode']} : {diag_reason.iloc[0]['diagnosisdesc']} on {diag_reason.iloc[0]['onsetdate']:%m/%d/%Y}\"\n",
    "        else:\n",
    "            human_readable_name = f\"Diagnosis of {diag_reason.iloc[0]['diagnosiscode']} : {diag_reason.iloc[0]['diagnosisdesc']}\"\n",
    "        print('+++++++++++++++++++++++++++++++++2')\n",
    "        if day_count in diagnosis_explanation_config.keys() and diag_label.lower() in diagnosis_explanation_config[\n",
    "            day_count]:\n",
    "            print('+++++++++++++++++++++++++++++++++3')\n",
    "            mapping_status = 'MAPPED'\n",
    "        elif (dx_attribution['all_time'] == 'all') and \\\n",
    "                (any(diag_all_string in diag_label.lower() for diag_all_string in\n",
    "                     diagnosis_explanation_config['all'])):\n",
    "            print('+++++++++++++++++++++++++++++++++4')\n",
    "            mapping_status = 'MAPPED'\n",
    "        else:\n",
    "            mapping_status = 'DATA FOUND'\n",
    "    else:\n",
    "        mapping_status = 'DATA_NOT_FOUND'\n",
    "        human_readable_name = ''\n",
    "    print('+++++++++++++++++++++++++++++++++5')\n",
    "    return pd.Series([human_readable_name, mapping_status], index=['a', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mapper(dx_attribution, diag_data, mpid_to_use, date_to_use, diagnosis_explanation_config):\n",
    "    human_readable_name = ''\n",
    "    mapping_status = 'NOT_mapped'\n",
    "    return pd.Series([human_readable_name, mapping_status], index=['a', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++++++++++=1\n",
      "+++++++++++++++++++++=2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human_readable_name</th>\n",
       "      <th>mapping_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [human_readable_name, mapping_status]\n",
       "Index: []"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnosis_explanation_config = get_config_value(\n",
    "            exp_dictionary,\n",
    "            client=client,\n",
    "            key='Patient_Diagnosis',\n",
    "            default_value={}\n",
    ")\n",
    "print('+++++++++++++++++++++=1')\n",
    "condition = (results.mapped_feature.str.startswith('cumsum_dx_')) & (\n",
    "        results.mapping_status == 'NOT_MAPPED')\n",
    "print('+++++++++++++++++++++=2')        \n",
    "# results.loc[condition, ['human_readable_name', 'mapping_status']] = (\n",
    "#     results\n",
    "#         .loc[condition]\n",
    "#         .apply(lambda x: _mapper(x,\n",
    "#                                         raw_data['patient_diagnosis'],\n",
    "#                                         x.masterpatientid,\n",
    "#                                         x.censusdate,\n",
    "#                                         diagnosis_explanation_config),\n",
    "#                axis=1)\n",
    "#         .values\n",
    "# )\n",
    "results.loc[condition, ['human_readable_name', 'mapping_status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition = (results.mapped_feature.str.startswith('cumsum_dx_')) & (results.feature_value == 1)\n",
    "len(results[condition]) > 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
