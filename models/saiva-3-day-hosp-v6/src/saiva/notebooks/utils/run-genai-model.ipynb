{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fcc2eba",
   "metadata": {},
   "source": [
    "## How to use?\n",
    "\n",
    "Install below libraries via terminal in the jupyter lab and then restart this notebook.\n",
    "1. `pip install awscli==1.32.4` \n",
    "2. `pip install boto3==1.34.3`\n",
    "\n",
    "You will need following credentails in order to run this notebook:\n",
    "```\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"\"\n",
    "os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"\"  \n",
    "os.environ[\"BEDROCK_ENDPOINT_URL\"] = \"\"\n",
    "```\n",
    "Once you set these OS variable you can push your data and run the bedrock model to get the results.\n",
    "\n",
    "Run the 00 notebook if you want to pull some data from DB. As we do not support the DB queries directly without the config we need that to be run before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ef0287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bedrock import get_bedrock_client\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "import json\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from saiva.model.shared.load_raw_data import fetch_training_data, fetch_training_cache_data\n",
    "from saiva.model.shared.database import DbEngine\n",
    "from saiva.model.shared.constants import LOCAL_TRAINING_CONFIG_PATH\n",
    "from saiva.training.utils import load_config\n",
    "from saiva.model.shared.utils import get_client_class\n",
    "# from saiva.model.shared.constants import CLIENT\n",
    "from eliot import to_file, log_message\n",
    "to_file(sys.stdout)\n",
    "\n",
    "\n",
    "CLIENT = \"avante\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a6adcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your bedrock creds here\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"\"\n",
    "os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"\"  \n",
    "os.environ[\"BEDROCK_ENDPOINT_URL\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b2216a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading training configs so we can connect to DB\n",
    "\n",
    "config = load_config(LOCAL_TRAINING_CONFIG_PATH)\n",
    "training_config = config.training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82331866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A query to get the notes data for avante, the client has to be changed in the 00 notebook config files.\n",
    "\n",
    "for organization_config in training_config.organization_configs:\n",
    "    engine = DbEngine()\n",
    "    saiva_engine = engine.get_postgresdb_engine()\n",
    "    client_sql_engine = engine.get_sqldb_engine(\n",
    "        db_name=organization_config.datasource.source_database_name,\n",
    "        credentials_secret_id=organization_config.datasource.source_database_credentials_secret_id,\n",
    "        query={\"driver\": \"ODBC Driver 17 for SQL Server\"}\n",
    "    )\n",
    "    \n",
    "    # verify connectivity\n",
    "    engine.verify_connectivity(client_sql_engine)\n",
    "    \n",
    "    client = \"avante\", \n",
    "    train_start_date = \"2023-01-01\"\n",
    "    test_end_date = \"2023-12-01\"\n",
    "    \n",
    "    facilities_query = \"SELECT FacilityID FROM view_ods_facility WHERE LineOfBusiness = 'SNF' AND Deleted='N'\"\n",
    "    facilities = pd.read_sql(facilities_query, con=client_sql_engine)\n",
    "    facilities = facilities[\"FacilityID\"].values.tolist()\n",
    "    facilities = \",\".join(str(facility_id) for facility_id in facilities)\n",
    "    \n",
    "    mpid_query = f'''\n",
    "                SELECT DISTINCT patientid, facilityid, masterpatientid, allergies, patientmrn\n",
    "                FROM view_ods_facility_patient\n",
    "                WHERE facilityid IN ({facilities}) and ((patientdeleted is NULL or patientdeleted='N') and \n",
    "                (masterpatientdeleted  is NULL or masterpatientdeleted='N'))\n",
    "                '''\n",
    "    mpIds = pd.read_sql(mpid_query, con=client_sql_engine)\n",
    "    \n",
    "    notes_query = f\"\"\"select patientid, facilityid, progressnoteid, progressnotetype, createddate, effectivedate, sectionsequence,\n",
    "                        section, notetextorder, notetext, highrisk, showon24hr, showonshift\n",
    "                        from view_ods_progress_note\n",
    "                        where createddate between '{train_start_date}' and '{test_end_date}'\n",
    "                        and facilityid in ({facilities})\n",
    "                \"\"\"\n",
    "    notes_df = pd.read_sql(notes_query, con=client_sql_engine)\n",
    "    notes_df = notes_df.merge(mpIds[['facilityid', 'patientid', 'masterpatientid', 'patientmrn']],\n",
    "                    on=[\"patientid\", \"facilityid\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0079d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data here so we can use it to feed directly to GenAI model\n",
    "\n",
    "notes_df['createddate'] = pd.to_datetime(notes_df['createddate'])\n",
    "filtered_df = notes_df[(notes_df['createddate'] > '2023-10-01') & (notes_df['createddate'] < '2023-10-31')]\n",
    "notes_type = ['eMAR-Medication Administration Note', 'Encounter', '* General NURSING Note', 'Infection Note', 'Skilled Nursing Note',\n",
    "              'eMar - Shift Level Administration Note']\n",
    "filtered_df = filtered_df[filtered_df['progressnotetype'].isin(notes_type)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8b363a",
   "metadata": {},
   "source": [
    "## BedRock API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c88b662",
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3_bedrock, _ = get_bedrock_client(region=\"us-east-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdb1ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(text,\n",
    "                      max_tokens_to_sample=300,\n",
    "                      temperature=0.5,\n",
    "                      top_k=250,\n",
    "                      top_p=0.5,\n",
    "                      stop_sequences=[]\n",
    "                      ):\n",
    "        \"\"\"\n",
    "        A basic method to connect and get an output from bedrock models.\n",
    "        In future if there will be a parameter change in the function arguments then we will need to test that before making the change.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            body = json.dumps({\"prompt\": text,\n",
    "                        \"max_tokens_to_sample\":max_tokens_to_sample,\n",
    "                        \"temperature\":temperature,\n",
    "                        \"top_k\":top_k,\n",
    "                        \"top_p\":top_p,\n",
    "                        \"stop_sequences\":stop_sequences\n",
    "                        })\n",
    "\n",
    "            accept = 'application/json'\n",
    "            contentType = 'application/json'\n",
    "            response = boto3_bedrock.invoke_model(body=body, modelId='anthropic.claude-v2', accept=accept, contentType=contentType)\n",
    "            response_body = json.loads(response.get('body').read())\n",
    "            result = response_body.get('completion')\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            log_message(\n",
    "                message_type='error',\n",
    "                message=f'EXCEPTION: Error in connecting to Bedrock API. {e}'\n",
    "            )\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92069d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##############################################################################################################\n",
    "# prompt is one of the most needed item here. If you do not tweak this as per your need then you will fail to get good results.\n",
    "# So please update the below prompt as per your needs and do not commit those changes as this prompt is for example.\n",
    "# What is a good prompt anyway?\n",
    "#  A good prompt is with the following details\n",
    "#    - Assign a role to your model such as ML engineer, SNF Nurse etc\n",
    "#    - Provide example of what you want the model to find or do or take care of while doing the task\n",
    "#    - Create some rules that your model can follow to get you the desired output\n",
    "# ##############################################################################################################\n",
    "\n",
    "prompt = \"\"\" \"\\n\\nHuman:\"\n",
    "            Suppose you are a nurse at a Skilled Nursing Facility(SNF) and you take care of many patients at a facility.\n",
    "            Our main objective is to find words that can lead to indication of missing medication order. For example:\n",
    "            \n",
    "            1. \"Epoetin Alfa Solution 10000 UNIT/ML Inject 10000 unit subcutaneously one time a day every Tue, Thu, Sat for anemia\n",
    "            on order not available\" - here keyword is `order not available`\n",
    "            2. order on hold, per MD - here keyword is 'order on hold'\n",
    "            So our main goal is to collect such keywords. These are just examples so please try to use your knowledge to find similar keywords\n",
    "            Below is the progress note that you have to read and find any keywords that can we can use to catch such missing medications.\n",
    "            <text>\n",
    "                {progress_notes}\n",
    "            </text>\n",
    "            Your output should be a list of keywords or keywor example - ['order on hold'] or ['order on hold', `order not available`]\n",
    "            If there are not keywords then output should be only and only []. Do not write any text apart from empty list when no keywords.\n",
    "            Stricly obey the rules for giving the output. Do not write anything.\n",
    "            \n",
    "            Assistant:\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f3633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please update the following code block in order to define how you want to collect the results from model.\n",
    "results = []\n",
    "\n",
    "for index, row in filtered_df.iterrows():\n",
    "    try:\n",
    "        note = row['notetext']\n",
    "        text = prompt.format(progress_notes=note)\n",
    "\n",
    "        result = generate_text(text)\n",
    "        results.append(result)\n",
    "    except Exception as ex:\n",
    "        print(\"Error: \", ex)\n",
    "        results.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a3f9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the results as column in DF\n",
    "filtered_df['keywords'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e3b221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing it back as CSV for post run analysis\n",
    "filtered_df.to_csv(\"filtered_notes_with_genai.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
