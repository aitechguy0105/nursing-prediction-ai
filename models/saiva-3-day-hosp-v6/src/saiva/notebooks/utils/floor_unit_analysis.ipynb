{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For facilities having more than 100 patients.\n",
    "We want to send the reports unitwise/floorwise\n",
    "This code provides an analysis about \n",
    "- patient count per census date\n",
    "- unitwise patient count per censusdate\n",
    "- floorwise patient count per censusdate\n",
    "- recall at different cutoff ranks per month\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from saiva.model.shared.database import DbEngine\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### select the client, facilityid, start_date, end_date,cutoff_rank accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client='infinity-benchmark'\n",
    "facilityid=37\n",
    "start_date = '2020-04-01'\n",
    "end_date = '2020-09-30'\n",
    "cutoff_rank = 60\n",
    "\n",
    "month_mapper = {\n",
    "    4:'april',\n",
    "    5:'may',\n",
    "    6:'june',\n",
    "    7:'july',\n",
    "    8:'august',\n",
    "    9:'september'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = DbEngine()\n",
    "client_engine =  engine.get_sqldb_engine(clientdb_name=client)\n",
    "# initialising postgres engine\n",
    "postgres_engine =  engine.get_postgresdb_engine()\n",
    "assert client_engine.execute('select 1').fetchall() is not None # verify connectivity \n",
    "print('===== Connection with db established =====')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## patient count per censusdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_query = f\"\"\"\n",
    "select cast(censusdate AS DATE) as censusdate, count(*) as facility_patient_count\n",
    "from view_ods_daily_census_v2 a\n",
    "where a.facilityid ={facilityid}\n",
    "and censusdate>='{start_date}'\n",
    "and censusdate<='{end_date}'\n",
    "group by censusdate\n",
    "order by censusdate \n",
    "\"\"\"\n",
    "\n",
    "census_df = pd.read_sql(census_query, con=client_engine)\n",
    "census_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## patient count per unitid per censusdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_census_query = f\"\"\"\n",
    "select cast(censusdate AS DATE) as censusdate, unitid, count(*) as patient_count\n",
    "from view_ods_daily_census_v2 a\n",
    "left join view_ods_bed b\n",
    "on a.facilityid = b.facilityid\n",
    "and a.bedid = b.bedid\n",
    "where a.facilityid ={facilityid}\n",
    "and censusdate>='{start_date}'\n",
    "and censusdate<='{end_date}'\n",
    "group by censusdate, unitid\n",
    "order by censusdate \n",
    "\"\"\"\n",
    "\n",
    "unit_census_df = pd.read_sql(unit_census_query, con=client_engine)\n",
    "unit_census_df['unitid'] = 'unit_'+unit_census_df['unitid'].astype(str)+'_patient_count'\n",
    "unit_census_df = unit_census_df.pivot(index='censusdate', columns='unitid', values='patient_count').reset_index()\n",
    "unit_census_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining the above two results\n",
    "\n",
    "total_census_df = pd.merge(census_df,unit_census_df,on='censusdate',how='inner')\n",
    "total_census_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## patient count per floorid per censusdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floor_census_query = f\"\"\"\n",
    "select cast(censusdate AS DATE) as censusdate, floorid, count(*) as patient_count\n",
    "from view_ods_daily_census_v2 a\n",
    "left join view_ods_bed b\n",
    "on a.facilityid = b.facilityid\n",
    "and a.bedid = b.bedid\n",
    "where a.facilityid ={facilityid}\n",
    "and censusdate>='{start_date}'\n",
    "and censusdate<='{end_date}'\n",
    "group by censusdate, floorid\n",
    "order by censusdate \n",
    "\"\"\"\n",
    "\n",
    "floor_census_df = pd.read_sql(floor_census_query, con=client_engine)\n",
    "floor_census_df['floorid'] = 'floor_'+floor_census_df['floorid'].astype(str)+'_patient_count'\n",
    "floor_census_df = floor_census_df.pivot(index='censusdate', columns='floorid', values='patient_count').reset_index()\n",
    "\n",
    "floor_census_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining facilitywise,unitwise,floorwise results\n",
    "\n",
    "\n",
    "total_census_df = pd.merge(total_census_df, floor_census_df, on='censusdate', how='inner')\n",
    "total_census_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## recall at different cutoff ranks per month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_rank_list = [15,30,45,60]\n",
    "date_ranges = [('2020-04-01', '2020-04-30'), ('2020-05-01', '2020-05-31'), ('2020-06-01', '2020-06-30'), ('2020-07-01', '2020-07-31'), ('2020-08-01', '2020-08-31'), ('2020-09-01', '2020-09-30')]\n",
    "date_range_mapper = {\n",
    "    ('2020-04-01', '2020-04-30'):'april',\n",
    "    ('2020-05-01', '2020-05-31'):'may',\n",
    "    ('2020-06-01', '2020-06-30'):'june',\n",
    "    ('2020-07-01', '2020-07-31'):'july',\n",
    "    ('2020-08-01', '2020-08-31'):'august',\n",
    "    ('2020-09-01', '2020-09-30'):'september',\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(columns=['date_range','rank_cutoff','recall'])\n",
    "\n",
    "for cutoff_rank in cutoff_rank_list:\n",
    "    for date in date_ranges:\n",
    "        \n",
    "        transfersqlquery = f\"\"\"\n",
    "        select distinct DateOfTransfer, a.PatientID,b.MasterpatientID\n",
    "        from view_ods_hospital_transfers_transfer_log_v2 a\n",
    "        left join view_ods_facility_patient b\n",
    "        on a.patientid = b.patientid\n",
    "        and a.facilityid = b.facilityid\n",
    "        where a.facilityid={facilityid}\n",
    "        and DateOfTransfer>='{date[0]}'\n",
    "        and DateOfTransfer<='{date[1]}'\n",
    "        and planned='No'\n",
    "        order by DateOfTransfer asc\n",
    "        \"\"\"\n",
    "        \n",
    "        transfer_df = pd.read_sql(transfersqlquery, con=client_engine)\n",
    "        # patients who were actually transferred between the gven date range \n",
    "        transfer_df['DateOfTransfer'] = transfer_df['DateOfTransfer'].dt.normalize()\n",
    "\n",
    "        \n",
    "        # patient transfers reported by saiva model\n",
    "        query = f\"\"\"\n",
    "        select *\n",
    "        from daily_predictions dp \n",
    "        where\n",
    "        facilityid ={facilityid}\n",
    "        and predictionrank <={cutoff_rank}\n",
    "        and censusdate between '{date[0]}' and '{date[1]}'\n",
    "        order by censusdate, predictionrank \n",
    "        \"\"\"\n",
    "        predicted_df = pd.read_sql(query, postgres_engine)\n",
    "        \n",
    "        patient_who_went_to_hospital = [] #patient who went to the hospital\n",
    "        patient_went_patient_reported_intersection = [] #patients who went to the hospital and were reported by the model\n",
    "        \n",
    "        for date_range in pd.date_range(date[0], date[1]).tolist():\n",
    "        #     list of patient reported by saiva model on a particular date\n",
    "            patients_reported_by_model = predicted_df.loc[predicted_df['censusdate']==date_range,'masterpatientid'].tolist()\n",
    "            \n",
    "        #     for date to date+3 days, we find the people who were rehospitalized\n",
    "            for transferdate in pd.date_range(date_range, date_range + datetime.timedelta(days=3)).tolist():\n",
    "                # list of patient who went to the hospital\n",
    "                transferred_patient = transfer_df.loc[transfer_df['DateOfTransfer']==transferdate,'MasterpatientID'].tolist()\n",
    "                if transferred_patient:\n",
    "                    # if patients were actually transferred on a particular day\n",
    "#                   # we count the number of transfers \n",
    "                    # and we count the number of transfers correctly predicted by the model\n",
    "                    patient_who_went_to_hospital.extend(transferred_patient)\n",
    "                    patient_went_patient_reported_intersection.extend([patient for patient in transferred_patient if patient in patients_reported_by_model])\n",
    "        \n",
    "        recall = len(set(patient_went_patient_reported_intersection))/len(set(patient_who_went_to_hospital))\n",
    "        output.loc[-1] = [date, 'recall_at_rank_'+str(cutoff_rank), recall]\n",
    "        output.reset_index(drop=True,inplace=True)\n",
    "        \n",
    "output_pivoted = output.pivot(index='date_range', columns='rank_cutoff', values='recall').reset_index()\n",
    "output_pivoted.columns.name = None\n",
    "output_pivoted['date_range'] = output_pivoted['date_range'].map(date_range_mapper)\n",
    "output_pivoted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unitwise recall at different rank cutoffs per censusdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unitwise_output = pd.DataFrame(columns=['date_range', 'unitid', 'rank_cutoff', 'patient_distribution','recall'])\n",
    "unitwise_distribution_list= []\n",
    "for cutoff_rank in cutoff_rank_list:\n",
    "    for date in date_ranges:\n",
    "        \n",
    "        transfersqlquery = f\"\"\"\n",
    "        select distinct DateOfTransfer, a.PatientID,b.MasterpatientID\n",
    "        from view_ods_hospital_transfers_transfer_log_v2 a\n",
    "        left join view_ods_facility_patient b\n",
    "        on a.patientid = b.patientid\n",
    "        and a.facilityid = b.facilityid\n",
    "        where a.facilityid={facilityid}\n",
    "        and DateOfTransfer>'{date[0]}'\n",
    "        and DateOfTransfer<='{date[1]}'\n",
    "        and planned='No'\n",
    "        order by DateOfTransfer asc\n",
    "        \"\"\"\n",
    "        transfer_df = pd.read_sql(transfersqlquery, con=client_engine)\n",
    "        transfer_df['DateOfTransfer'] = transfer_df['DateOfTransfer'].dt.normalize()\n",
    "\n",
    "\n",
    "        # patient transfer reported by saiva model\n",
    "        daily_predictions_query = f\"\"\"\n",
    "        select *\n",
    "        from daily_predictions dp \n",
    "        where\n",
    "        facilityid ={facilityid}\n",
    "        and predictionrank <={cutoff_rank}\n",
    "        and censusdate between '{date[0]}' and '{date[1]}'\n",
    "        order by censusdate, predictionrank \n",
    "        \"\"\"\n",
    "        predicted_df = pd.read_sql(daily_predictions_query, postgres_engine)\n",
    "        \n",
    "        census_query = f\"\"\"\n",
    "        select distinct clientid, c.masterpatientid, censusdate, a.facilityid, a.bedid, b.unitid, b.floorid\n",
    "        from view_ods_daily_census_v2 a\n",
    "        left join view_ods_bed b \n",
    "        on a.facilityid = b.facilityid\n",
    "        and a.bedid = b.bedid \n",
    "        left join view_ods_facility_patient c\n",
    "        on c.patientid = a.clientid\n",
    "        and c.facilityid = a.facilityid\n",
    "        where a.facilityid={facilityid}\n",
    "        and censusdate>='{date[0]}'\n",
    "        and censusdate<='{date[1]}'\n",
    "        order by censusdate,clientid\n",
    "        \"\"\"\n",
    "        census_df = pd.read_sql(census_query, client_engine)\n",
    "        unique_unitids = census_df['unitid'].unique().tolist()\n",
    "        patient_went_patient_reported_intersection = []\n",
    "        patient_who_went_to_hospital = []\n",
    "        total_patients_reported_by_model = predicted_df['masterpatientid'].tolist()\n",
    "        \n",
    "        for date_range in pd.date_range(date[0], date[1]).tolist():\n",
    "        #     list of patient reported by saiva model on a particular date\n",
    "            patients_reported_by_model = predicted_df.loc[predicted_df['censusdate']==date_range,'masterpatientid'].tolist()\n",
    "            temp_unitwise_distribution = census_df.loc[(census_df['masterpatientid'].isin(patients_reported_by_model)) & (census_df['censusdate']==date_range)]['unitid'].value_counts().reset_index()\n",
    "            temp_unitwise_distribution['censusdate']=date_range\n",
    "            temp_unitwise_distribution['rank']=cutoff_rank\n",
    "            temp_unitwise_distribution.rename(columns = {'unitid':'count','index':'unitid',}, inplace = True)\n",
    "            temp_unitwise_distribution['unitid'].fillna(0,inplace=True)\n",
    "            temp_unitwise_distribution = pd.pivot_table(temp_unitwise_distribution, values = 'count', index=['censusdate','rank'], columns = ['unitid']).reset_index()\n",
    "            unitwise_distribution_list.append(temp_unitwise_distribution)\n",
    "        #     for date to date+3 days, we find the people who were rehospitalized\n",
    "        \n",
    "            for transferdate in pd.date_range(date_range, date_range + datetime.timedelta(days=3)).tolist():\n",
    "                # list of patient who went to the hospital\n",
    "                transferred_patient = transfer_df.loc[transfer_df['DateOfTransfer']==transferdate,'MasterpatientID'].tolist()\n",
    "                if transferred_patient:\n",
    "                    patient_who_went_to_hospital.extend(transferred_patient)\n",
    "                    patient_went_patient_reported_intersection.extend([patient for patient in transferred_patient if patient in patients_reported_by_model])\n",
    "        \n",
    "        patient_went_patient_reported_intersection = list(set(patient_went_patient_reported_intersection))\n",
    "        patient_who_went_to_hospital = list(set(patient_who_went_to_hospital))\n",
    "\n",
    "        for unit in unique_unitids:\n",
    "            patient_distribution = len([patient for patient in total_patients_reported_by_model if patient in census_df.loc[census_df['unitid']==unit,'masterpatientid'].tolist()])\n",
    "            numerator = [patient for patient in patient_went_patient_reported_intersection if patient in census_df.loc[census_df['unitid']==unit,'masterpatientid'].tolist()]\n",
    "            denominator = [patient for patient in patient_who_went_to_hospital if patient in census_df.loc[census_df['unitid']==unit,'masterpatientid'].tolist()]\n",
    "            if len(denominator):\n",
    "                recall = len(numerator) /len(denominator)\n",
    "            else:\n",
    "                recall = 0\n",
    "            unitwise_output.loc[-1] = [date, unit, 'recall_at_rank_cutoff_'+str(cutoff_rank), patient_distribution, recall]\n",
    "            unitwise_output.reset_index(drop=True,inplace=True)\n",
    "            \n",
    "unitwise_distribution_list = [i for i in unitwise_distribution_list if i.shape[0]!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unitwise_distribution = pd.concat(unitwise_distribution_list)\n",
    "unitwise_distribution.fillna(0,inplace=True)\n",
    "\n",
    "for i,col in enumerate(unitwise_distribution.columns.values):\n",
    "    if type(col)==int:\n",
    "        unitwise_distribution[col] = unitwise_distribution[col].astype(int)\n",
    "\n",
    "unitwise_distribution.sort_values(by=['censusdate','rank'],inplace=True)\n",
    "unitwise_distribution.columns = ['unit_'+str(col)+'_patient_count' if type(col)==int else col for col in unitwise_distribution.columns ]\n",
    "unitwise_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unitwise rank mean,max,min,meadin, std. dev. at different rank cutoffs and grouped on a monthly basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'> Note: Please manually fill the unitids names in the below groupby aggregation code(line 3)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthwise_unitwise_distribution = unitwise_distribution.copy()\n",
    "monthwise_unitwise_distribution['month'] = pd.DatetimeIndex(monthwise_unitwise_distribution['censusdate']).month\n",
    "monthwise_unitwise_distribution['month'] = monthwise_unitwise_distribution['month'].map(month_mapper)\n",
    "monthwise_unitwise_distribution = monthwise_unitwise_distribution.groupby(['month','rank'],sort=False,).agg({'unit_2107_patient_count':['max','min','mean','median','std'],'unit_2117_patient_count':['max','min','mean','median','std'],'unit_2127_patient_count':['max','min','mean','median','std'], 'unit_2128_patient_count':['max','min','mean','median','std'],'unit_2137_patient_count':['max','min','mean','median','std'],'unit_2147_patient_count':['max','min','mean','median','std'] }).reset_index()\n",
    "monthwise_unitwise_distribution = monthwise_unitwise_distribution.round(2)\n",
    "monthwise_unitwise_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### writing results in excelsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(f'{client}_faciity{facilityid}_analysis.xlsx')\n",
    "total_census_df.to_excel(writer,'daily_census_count', index=False)\n",
    "output_pivoted.to_excel(writer,'monthwise_recall_at_different_ranks', index=False)\n",
    "unitwise_distribution.to_excel(writer,'daily_unitwise_reportcount', index=False)\n",
    "monthwise_unitwise_distribution.to_excel(writer,'monthwise_unitwise_reportcount_aggregation_analysis')\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
