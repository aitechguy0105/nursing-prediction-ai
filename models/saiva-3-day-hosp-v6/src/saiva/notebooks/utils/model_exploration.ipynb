{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781b9290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import mlflow\n",
    "import shap\n",
    "\n",
    "import sys\n",
    "\n",
    "from saiva.training import load_lgb_model, download_model_from_mlflow, load_x_y_idens\n",
    "from saiva.training.data_models import BaseModel\n",
    "from saiva.training.metrics import run_test_set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a379a24",
   "metadata": {},
   "source": [
    "## =================== Experiment exploration ==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d97b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor = 'metrics.TEST_02_upt_recall_at_rank_15'\n",
    "experiment_id = 466\n",
    "\n",
    "df = mlflow.search_runs(experiment_ids=[experiment_id])\n",
    "\n",
    "try:\n",
    "    best_run_config = df.nlargest(1, monitor).iloc[0].to_dict()\n",
    "except:\n",
    "    best_run_config = dict()\n",
    "    \n",
    "BEST_AUC = best_run_config.get('metrics.TEST_01_aucroc', None)\n",
    "LEARNING_RATE = best_run_config.get('params.hp__learning_rate', None)\n",
    "NUM_ITERATIONS = best_run_config.get('params.p__best_iteration', None)\n",
    "MODELID = best_run_config.get('run_id', None)\n",
    "    \n",
    "print(f'Best model has AUC = {BEST_AUC}')\n",
    "print(f'With total estimators = {NUM_ITERATIONS}')\n",
    "print(f'And learning rate = {LEARNING_RATE}')\n",
    "print(f'Model ID = {MODELID}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0eba918b",
   "metadata": {},
   "source": [
    "## ============== Download Model from MLflow ==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372f9e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelid = '4e56c8c354554a0bacd52765b9521897'\n",
    "download_model_from_mlflow(modelid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1559f3e",
   "metadata": {},
   "source": [
    "## =============== Load Model from local folder ==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f3be5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelid = '4e56c8c354554a0bacd52765b9521897'\n",
    "model = load_lgb_model(modelid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0f15372",
   "metadata": {},
   "source": [
    "## ============= List Feature Importance of the model =============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e59f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = (\n",
    "    pd.DataFrame({\n",
    "        'feature': model.feature_name(),\n",
    "        'importance': model.feature_importance(importance_type='gain'),  # split\n",
    "    })\n",
    "    .sort_values('importance', ascending=False)\n",
    ")\n",
    "feature_imp.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f138c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(model, max_num_features=50, figsize=(15,15))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "701e5351",
   "metadata": {},
   "source": [
    "## ============== Run test on pre-loaded model ==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005e208e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, idens = load_x_y_idens('/data/processed/', 'model_upt', 'test')\n",
    "\n",
    "run_test_set(\n",
    "    model,\n",
    "    modelid,\n",
    "    modelid,\n",
    "    test_start_date = idens['censusdate'].min().strftime('%Y-%m-%d'),\n",
    "    test_end_date = idens['censusdate'].max().strftime('%Y-%m-%d'),\n",
    "    x_df = x,\n",
    "    target_3_day = y,\n",
    "    idens = idens,\n",
    "    model_type = 'upt',\n",
    "    threshold = 0.15,\n",
    "    log_in_mlflow = False\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "846c755f",
   "metadata": {},
   "source": [
    "## ============== Run Shap Explanations for Test Set =============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050ac07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shap takes lot of time to run across all test dataset. Since certain index and run shap for faster results \n",
    "n = 50\n",
    "\n",
    "explainer = shap.TreeExplainer(model)\n",
    "subset = x.sample(n)\n",
    "shap_values = explainer.shap_values(subset)\n",
    "\n",
    "shap_results = []\n",
    "\n",
    "for i, (idx, row) in enumerate(subset.iterrows()):\n",
    "    shaps = pd.DataFrame(\n",
    "        {\n",
    "            \"feature\": subset.columns,\n",
    "            \"attribution_score\": shap_values[i] if (model.params.get('objective') != 'binary') \\\n",
    "                                                else shap_values[1][i],\n",
    "            \"feature_value\": subset.loc[idx],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    shaps[\"masterpatientid\"] = idens.iloc[idx].masterpatientid\n",
    "    shaps[\"facilityid\"] = idens.iloc[idx].facilityid\n",
    "    shaps[\"censusdate\"] = idens.iloc[idx].censusdate\n",
    "\n",
    "    shap_results.append(shaps)\n",
    "\n",
    "results = pd.concat(shap_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca11b92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.query('attribution_score > 0.1').sort_values(by=['attribution_score'], ascending=False)['feature'].value_counts().head(25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
