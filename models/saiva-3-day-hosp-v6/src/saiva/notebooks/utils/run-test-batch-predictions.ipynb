{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb0401d5",
   "metadata": {},
   "source": [
    "## How to run this?\n",
    "\n",
    "1. You need to run the training notebook from `01` to `04` by making necessary changes that each notebook asks.\n",
    "    1.1 If you want to generate the first 2 batch data-cards, please follow the necessary notebooks for that.\n",
    "2. At the end of `04` notebook we store the `final_df.parquet` in the `/data/processed/` folder.\n",
    "3. We use that file here and mimic the prediction pipeline for entire batch.\n",
    "4. Change the model ID in the notebook in **Download Model from MLflow** section.\n",
    "5. Change the experiment ID in the **Experiment exploration** if you want to check some stats. We do not use it in predictions though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ad8f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import mlflow\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import timedelta, datetime\n",
    "import re\n",
    "import pickle\n",
    "from omegaconf import OmegaConf\n",
    "from eliot import start_action, start_task, log_message, to_file\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "from saiva.training import load_lgb_model, download_model_from_mlflow, load_x_y_idens\n",
    "from saiva.training.data_models import BaseModel\n",
    "from saiva.training.metrics import run_test_set\n",
    "from saiva.model.shared.utils import get_client_class, url_encode_cols\n",
    "from saiva.model.explanations.config import FEATURE_TYPE_MAPPING\n",
    "\n",
    "from batch_preds_utils import prep, download_model_cat_cols_list_mlflow, preprocess_final_df\n",
    "\n",
    "to_file(sys.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a40da3",
   "metadata": {},
   "source": [
    "## ============== Define your constants here ==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeb95df",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelid = '8a1c3903cf1e4e09ba3c491a7b999603'\n",
    "CLIENT = \"avante\"\n",
    "MODEL_TYPE = \"MODEL_UPT\"\n",
    "TEST_START_DATE = \"2024-01-01\"\n",
    "TEST_END_DATE = \"2024-01-31\"\n",
    "FACILITY_IDS = None  ## keep None if you want to run prediction on all facilities else provide list of facilities as integer like [1,3,5,7]\n",
    "\n",
    "processed_path = Path('/data/processed/')\n",
    "filename = \"final_df.parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef4be0a",
   "metadata": {},
   "source": [
    "## ============== Download Model from MLflow ==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f299408b",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_model_from_mlflow(modelid)\n",
    "download_model_cat_cols_list_mlflow(modelid, \"/data/model/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a448cfd",
   "metadata": {},
   "source": [
    "## =============== Load Model from local folder ==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b72394",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model = load_lgb_model(modelid)\n",
    "model = BaseModel(model_name=MODEL_TYPE,\n",
    "                  model_type=\"lgb\",\n",
    "                  model=lgb_model)\n",
    "model.truncate_v6_suffix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786ffca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load categorical columns from pickle\n",
    "with open(f'/data/model/cate_columns.pickle', 'rb') as f:\n",
    "    cate_cols = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06accc0f",
   "metadata": {},
   "source": [
    "## ============== Run inference on feature engineered data ==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5834ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDEN_COLS = ['censusdate', 'facilityid', 'masterpatientid', 'LFS', 'primaryphysicianid',\n",
    "         'payername', 'to_from_type', 'client', 'admissionstatus', f'positive_date_{MODEL_TYPE.lower()}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da45471",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = preprocess_final_df(os.path.join(processed_path, filename),\n",
    "                          MODEL_TYPE.lower(),\n",
    "                          TEST_START_DATE,\n",
    "                          TEST_END_DATE,\n",
    "                          FACILITY_IDS\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eef5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_x, test_target_3_day, test_idens = prep(test,\n",
    "                                             model,\n",
    "                                             client=CLIENT,\n",
    "                                             iden_cols=IDEN_COLS,\n",
    "                                             pandas_categorical=model.model.pandas_categorical,\n",
    "                                             categorical_columns=cate_cols,\n",
    "                                             target_col=f'target_3_day_{MODEL_TYPE.lower()}')\n",
    "\n",
    "test_x.shape, test_target_3_day.shape, test_idens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec353a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are storing the created test_x, test_y and idens in the /data/test folder so you can run another client featurization if you want.\n",
    "if not os.path.exists('/data/test/'):\n",
    "    os.makedirs('/data/test')\n",
    "\n",
    "with open(f'/data/test/final-test_x_{MODEL_TYPE.lower()}.pickle','wb') as f: pickle.dump(test_x, f, protocol=4)\n",
    "with open(f'/data/test/final-test_target_3_day_{MODEL_TYPE.lower()}.pickle','wb') as f: pickle.dump(test_target_3_day, f, protocol=4)\n",
    "with open(f'/data/test/final-test_idens_{MODEL_TYPE.lower()}.pickle','wb') as f: pickle.dump(test_idens, f, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ff981d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, idens = load_x_y_idens('/data/test/', MODEL_TYPE.lower() , 'test')\n",
    "\n",
    "\n",
    "test_total_aucroc, test_recall, test_recall_LE30, test_recall_G30, test_short_term_recall, test_long_term_recall = run_test_set(\n",
    "    model,\n",
    "    modelid,\n",
    "    modelid,\n",
    "    test_start_date = test['censusdate'].min().strftime('%Y-%m-%d'),\n",
    "    test_end_date = test['censusdate'].max().strftime('%Y-%m-%d'),\n",
    "    x_df = x,\n",
    "    target_3_day = y,\n",
    "    idens = idens,\n",
    "    model_type = MODEL_TYPE.lower(),\n",
    "    dataset = 'TEST',\n",
    "    log_in_mlflow=False,\n",
    "    threshold=0.15\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
