{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:15: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from saiva.model.shared.utils import get_client_class, get_memory_usage\n",
    "from saiva.model.shared.constants import CLIENT\n",
    "import seaborn as sns\n",
    "from scipy import stats as ss\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_path = Path('/data/processed')\n",
    "total_df = pd.read_parquet(processed_path/'02-result.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1096254, 4097)\n",
      "(548127, 4097)\n"
     ]
    }
   ],
   "source": [
    "print(total_df.shape)\n",
    "df = total_df.sample(frac=.5)\n",
    "print(df.shape)\n",
    "df['hosp_target_3_day_hosp'] = df.hosp_target_3_day_hosp.fillna(False)\n",
    "df['hosp_target_7_day_hosp'] = df.hosp_target_7_day_hosp.fillna(False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ================== Types of columns ==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cumsum columns 2868\n",
      "dx columns 381\n",
      "med columns 1413\n",
      "order columns 378\n",
      "alerts columns 15\n",
      "lab columns 681\n",
      "na_indictator columns 990\n",
      "vitals diff columns 44\n",
      "vitals rol columns 44\n",
      "vitals columns 22\n",
      "demo columns 99\n",
      "date columns 22\n",
      "hosp columns 2\n",
      "identity columns 5\n",
      "target columns 2\n"
     ]
    }
   ],
   "source": [
    "cumsum_cols = [col for col in df.columns if col.startswith('cumsum')]\n",
    "dx_cols = [col for col in cumsum_cols if '_dx_' in col]\n",
    "med_cols = [col for col in cumsum_cols if '_med_' in col]\n",
    "order_cols = [col for col in cumsum_cols if '_order_' in col]\n",
    "alert_cols = [col for col in cumsum_cols if '_alert_' in col]\n",
    "labs_cols = [col for col in cumsum_cols if '_labs__' in col]\n",
    "\n",
    "print('cumsum columns',len(cumsum_cols))\n",
    "print('dx columns',len(dx_cols))\n",
    "print('med columns',len(med_cols))\n",
    "print('order columns',len(order_cols))\n",
    "print('alerts columns',len(alert_cols))\n",
    "print('lab columns',len(labs_cols))\n",
    "\n",
    "na_indictator_cols = [col for col in df.columns if col.startswith('na_indictator_')]\n",
    "print('na_indictator columns',len(na_indictator_cols))\n",
    "diff_cols = [col for col in df.columns if col.startswith('diff_')]\n",
    "print('vitals diff columns',len(diff_cols))\n",
    "rol_cols = [col for col in df.columns if col.startswith('rol')]\n",
    "print('vitals rol columns',len(rol_cols))\n",
    "vtl_cols = [col for col in df.columns if col.startswith('vtl_')]\n",
    "print('vitals columns',len(vtl_cols))\n",
    "demo_cols = [col for col in df.columns if col.startswith('demo_')]\n",
    "print('demo columns',len(demo_cols))\n",
    "date_cols = [col for col in df.columns if col.startswith('censusdate_') or col.startswith('dateofbirth_')]\n",
    "print('date columns',len(date_cols))\n",
    "hosp_cols = ['hosp_count_prior_hosp', 'hosp_days_since_last_hosp']\n",
    "print('hosp columns',len(hosp_cols))\n",
    "identity_cols = ['censusdate', 'masterpatientid', 'facilityid', 'bedid', 'client']\n",
    "target_cols = [col for col in df.columns if 'target' in col]\n",
    "print('identity columns',len(identity_cols))\n",
    "print('target columns',len(target_cols))\n",
    "target_cols = ['hosp_target_3_day_hosp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hosp_target_7_day_hosp'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = cumsum_cols + target_cols + identity_cols + demo_cols + rol_cols + diff_cols + vtl_cols + na_indictator_cols + hosp_cols + date_cols\n",
    "# get remaining columns\n",
    "remaining_df = df[df.columns.difference(cols)]\n",
    "remaining_df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## =================== Correlation ==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(dataset, threshold):\n",
    "    lst =[]\n",
    "    corr_matrix = dataset.corr()\n",
    "    column_length = len(corr_matrix.columns)\n",
    "    for i in range(column_length):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) >= threshold: # we are interested in absolute coeff value\n",
    "                colname1 = corr_matrix.columns[i]\n",
    "                colname2 = corr_matrix.columns[j]\n",
    "                lst.extend([[colname1,colname2, corr_matrix.iloc[i, j]]])\n",
    "    temp_df = pd.DataFrame(lst,columns=['column1','column2','correlation'])\n",
    "    temp_df.sort_values('correlation',ascending=False,inplace=True)\n",
    "                \n",
    "    return temp_df, corr_matrix \n",
    "\n",
    "def target_correlation(dataset, target_cols, threshold):\n",
    "    lst =[]\n",
    "    corr_matrix = dataset.corr()\n",
    "    column_length = len(corr_matrix.columns)\n",
    "    for i in range(column_length):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) >= threshold:\n",
    "                colname1 = corr_matrix.columns[i]\n",
    "                colname2 = corr_matrix.columns[j]\n",
    "                if colname1 in target_cols or colname2 in target_cols:\n",
    "                    lst.extend([[colname1,colname2, corr_matrix.iloc[i, j]]])\n",
    "    temp_df = pd.DataFrame(lst,columns=['column1','column2','correlation'])\n",
    "    temp_df.sort_values('correlation',ascending=False,inplace=True)\n",
    "                \n",
    "    return temp_df, corr_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column1</th>\n",
       "      <th>column2</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>censusdate_Week</td>\n",
       "      <td>censusdate_Month</td>\n",
       "      <td>0.977162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dateofbirth_Week</td>\n",
       "      <td>dateofbirth_Month</td>\n",
       "      <td>0.962279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            column1            column2  correlation\n",
       "0  censusdate_Week   censusdate_Month   0.977162   \n",
       "1  dateofbirth_Week  dateofbirth_Month  0.962279   "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df = df[date_cols]\n",
    "df_corr,corr_matrix = correlation(_df,.8)\n",
    "df_corr\n",
    "\n",
    "# more analysis on the frequency of data - vitals\n",
    "# 30 day window & all time window\n",
    "# Na filling \n",
    "# hyper opt training\n",
    "# parallel processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr.to_csv('cr_date.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column1</th>\n",
       "      <th>column2</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [column1, column2, correlation]\n",
       "Index: []"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df = df[date_cols + target_cols]\n",
    "df_corr,corr_matrix = target_correlation(_df,target_cols, 0.5)\n",
    "df_corr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## =================== Correlation Heat Map ==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(11, 15)) \n",
    "heatmap = sns.heatmap(corr_matrix, \n",
    "                      square = True,\n",
    "                      linewidths = .5,\n",
    "                      cmap = 'coolwarm',\n",
    "                      cbar_kws = {'shrink': .4, \n",
    "                                'ticks' : [-1, -.5, 0, 0.5, 1]},\n",
    "                      vmin = -1, \n",
    "                      vmax = 1,\n",
    "                      annot = True,\n",
    "                      annot_kws = {\"size\": 12})\n",
    "#add the column names as labels\n",
    "ax.set_yticklabels(corr_matrix.columns, rotation = 0)\n",
    "ax.set_xticklabels(corr_matrix.columns)\n",
    "sns.set_style({'xtick.bottom': True}, {'ytick.left': True})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## =================== Categorical Correlation ==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cramers_v(col1, col2):\n",
    "    confusion_matrix = pd.crosstab(col1,col2)\n",
    "    chi2 = ss.chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    phi2 = chi2/n\n",
    "    r,k = confusion_matrix.shape\n",
    "    phi2corr = max(0, phi2-((k-1)*(r-1))/(n-1))\n",
    "    rcorr = r-((r-1)**2)/(n-1)\n",
    "    kcorr = k-((k-1)**2)/(n-1)\n",
    "    return np.sqrt(phi2corr/min((kcorr-1),(rcorr-1)))\n",
    "\n",
    "\n",
    "cat_cols = demo_cols\n",
    "lst =[]\n",
    "for i in range(len(cat_cols)):\n",
    "    for j in range(len(cat_cols)):\n",
    "        if i != j:\n",
    "            colname1 = cat_cols[i]\n",
    "            colname2 = cat_cols[j]\n",
    "            corr = cramers_v(df[colname1], df[colname2])\n",
    "            lst.extend([[colname1,colname2,corr]])\n",
    "temp_df = pd.DataFrame(lst,columns=['column1','column2','correlation'])\n",
    "temp_df.sort_values('correlation',ascending=False,inplace=True)\n",
    "temp_df[temp_df['correlation'] > 0.5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ========== Mutual Information =================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6.29390013e-04, 4.01312087e-04, 2.97718926e-05, 1.24987139e-03,\n",
       "       2.57054523e-05, 8.94196900e-04, 1.11550361e-03, 4.65247559e-04,\n",
       "       2.08214724e-04, 3.25365184e-04, 5.57329018e-04, 0.00000000e+00,\n",
       "       3.56419500e-04, 3.81318941e-04, 2.50198797e-04, 5.46098608e-04,\n",
       "       4.89236811e-04, 2.07178553e-04, 1.20349541e-03, 3.26883026e-04,\n",
       "       3.05834570e-04, 0.00000000e+00, 7.06512385e-04, 8.21554014e-04,\n",
       "       1.24135693e-04, 1.61377511e-03, 4.21487853e-04, 1.22482124e-03,\n",
       "       1.71350643e-03, 6.91066961e-04, 7.31633365e-04, 4.38595262e-04,\n",
       "       6.82785919e-04, 3.50232967e-04, 7.95134028e-04, 4.52938125e-04,\n",
       "       6.70349997e-04, 7.76446491e-04, 2.76156803e-04, 2.16806924e-04,\n",
       "       1.31087379e-03, 4.60974199e-04, 3.45691144e-04, 2.08660022e-04])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif, mutual_info_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# calculate the mutual information between the variables and the target\n",
    "# this returns the mutual information value of each feature.\n",
    "# the smaller the value the less information the feature has about the target\n",
    "\n",
    "X_train = df[diff_cols]\n",
    "y_train = df[target_cols]\n",
    "mi = mutual_info_classif(X_train.fillna(0), y_train)\n",
    "mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's add the variable names and order the features\n",
    "# according to the MI for clearer visualisation\n",
    "mi = pd.Series(mi)\n",
    "mi.index = X_train.columns\n",
    "mi = mi.sort_values(ascending=False)\n",
    "mi.to_csv('mi-vitals-diff2.csv', header=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## =============== Play =================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_path = Path('/data/processed')\n",
    "combined = pd.read_parquet(processed_path/'01-result.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vtl_median_BP - Systolic',\n",
       " 'vtl_median_Blood Sugar',\n",
       " 'vtl_median_Height',\n",
       " 'vtl_median_O2 sats',\n",
       " 'vtl_median_Pain Level',\n",
       " 'vtl_median_Pulse',\n",
       " 'vtl_median_Respiration',\n",
       " 'vtl_median_Temperature',\n",
       " 'vtl_median_Weight',\n",
       " 'vtl_std_BP - Systolic',\n",
       " 'vtl_std_Blood Sugar',\n",
       " 'vtl_std_Height',\n",
       " 'vtl_std_O2 sats',\n",
       " 'vtl_std_Pain Level',\n",
       " 'vtl_std_Pulse',\n",
       " 'vtl_std_Respiration',\n",
       " 'vtl_std_Temperature',\n",
       " 'vtl_std_Weight',\n",
       " 'vtl_median_diastolicvalue',\n",
       " 'vtl_std_diastolicvalue',\n",
       " 'vtl_warnings',\n",
       " 'vtl_bmi']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vtl_cols = [col for col in combined.columns if col.startswith('vtl')]\n",
    "\n",
    "ffilled = combined.groupby('masterpatientid')[vtl_cols].fillna(method='ffill')\n",
    "ffilled['masterpatientid'] = df.masterpatientid\n",
    "vtl_cols = [col for col in vtl_cols if '_min_' not in col and '_max_' not in col]\n",
    "vtl_cols"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ============== check why labs features not coming up ============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_patient_lookup = result_dict['master_patient_lookup'].copy(deep=True)\n",
    "census = result_dict['patient_census'].copy(deep=True)\n",
    "\n",
    "base = census.merge(\n",
    "    master_patient_lookup,\n",
    "    how='inner',\n",
    "    left_on=['masterpatientid'],\n",
    "    right_on=['masterpatientid']\n",
    ")\n",
    "base.shape\n",
    "\n",
    "\n",
    "\n",
    "labs_df = result_dict['patient_lab_results'].copy(deep=True)\n",
    "\n",
    "labs_df['resultdate'] = labs_df['resultdate'].dt.normalize()\n",
    "base['censusdate'] = base['censusdate'].dt.normalize()\n",
    "\n",
    "merged_df = base.merge(\n",
    "        labs_df,\n",
    "        how='inner',\n",
    "        left_on=['masterpatientid', 'censusdate'],\n",
    "        right_on=['masterpatientid', 'resultdate']\n",
    "    )\n",
    "print(labs_df.shape)\n",
    "print(merged_df.shape)\n",
    "\n",
    "\n",
    "# Labs starting and ending date\n",
    "labs_df = result_dict['patient_lab_results'].copy(deep=True)\n",
    "labs_df['resultdate'] = labs_df['resultdate'].dt.normalize()\n",
    "for fid in list(labs_df.facilityid.unique()):\n",
    "    print(f\"{fid}  - {labs_df[labs_df['facilityid'] == fid]['resultdate'].min()} - {labs_df[labs_df['facilityid'] == fid]['resultdate'].max()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
