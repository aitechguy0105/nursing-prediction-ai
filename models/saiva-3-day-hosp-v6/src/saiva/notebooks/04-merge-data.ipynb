{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from eliot import start_action, start_task, to_file, log_message\n",
    "from saiva.model.shared.utils import get_client_class, get_memory_usage\n",
    "to_file(sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_path = Path('/data/processed')\n",
    "processed_file_names = {\n",
    "    'Demographics': 'demo_df.parquet',\n",
    "    'Vitals': 'vitals_df.parquet',\n",
    "    'Orders': 'orders_df.parquet',\n",
    "    'Alerts': 'alerts_df.parquet',\n",
    "    'Medications': 'meds_df.parquet',\n",
    "    'Transfers': 'rehosp_df.parquet',\n",
    "    'Admissions': 'admissions_df.parquet',\n",
    "    'Diagnoses': 'diagnosis_df.parquet',\n",
    "    'Labs': 'labs_df.parquet',\n",
    "    'ProgressNotes': 'notes_df.parquet',\n",
    "    'Immunizations': 'immuns_df.parquet',\n",
    "    'Risks': 'risks_df.parquet',\n",
    "    'Assessments': 'assessments_df.parquet',\n",
    "    'Adt': 'adt_df.parquet',\n",
    "    'Mds': 'mds_df.parquet'\n",
    "}\n",
    "processed_file_paths = {group: processed_path/file_name for group, file_name in processed_file_names.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "feature_groups = dict()\n",
    "for i, (group, file_name) in enumerate(processed_file_names.items()):\n",
    "    print('merging', file_name)\n",
    "    file_path = processed_path/file_name\n",
    "    if i == 0:\n",
    "        final_df = pd.read_parquet(file_path)\n",
    "        feature_groups[group] = list(final_df.columns)\n",
    "    elif Path.exists(file_path):\n",
    "        df = pd.read_parquet(file_path)\n",
    "        reordered_cols = list(df.columns.sort_values())\n",
    "        df = df[reordered_cols]\n",
    "        final_df = final_df.merge(\n",
    "            df,\n",
    "            how='left',\n",
    "            on=['masterpatientid', 'facilityid', 'censusdate']\n",
    "        )\n",
    "        feature_groups[group] = list(df.columns)\n",
    "        del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# drop unwanted columns\n",
    "columns_to_drop = final_df.columns[\n",
    "    (final_df.columns.str.contains('_masterpatientid|_facilityid|_x$|_y$|^patientid'))|(final_df.columns.duplicated())\n",
    "].tolist()\n",
    "if len(columns_to_drop) > 0:\n",
    "    final_df.drop(columns_to_drop, axis=1, inplace = True)\n",
    "\n",
    "print('Number of columns in the dataframe:', final_df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Write to new parquet file\n",
    "final_df.to_parquet(processed_path/'final_df.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_columns = ['masterpatientid', 'facilityid', 'censusdate', 'client', 'date_of_transfer', 'na_indictator_date_of_transfer']\n",
    "feature_groups = {\n",
    "    group: [\n",
    "        feat for feat in features if (feat in final_df.columns) and not (feat in exclude_columns)\n",
    "    ] for group, features in feature_groups.items()\n",
    "}\n",
    "with open('./feature_groups.json', 'w') as outfile: json.dump(feature_groups, outfile)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_memory_usage(final_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_cols = [i for i in final_df.columns if final_df[i].isna().any()]\n",
    "len(nan_cols)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
