{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "923c5d56",
   "metadata": {},
   "source": [
    "## Open this in Jupyter Tree \n",
    "\n",
    "### Restart kernel after the below packages are installed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261bbd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns',None)\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import boto3\n",
    "from eliot import log_message\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.engine.url import URL\n",
    "from sqlalchemy import text\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly.subplots import make_subplots\n",
    "from PIL import Image\n",
    "\n",
    "from saiva.model.shared.constants import MODEL_TYPE\n",
    "from saiva.model.shared.utils import get_client_class\n",
    "from saiva.training import load_x_y_idens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69c2d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from saiva.model.shared.constants import saiva_api, LOCAL_TRAINING_CONFIG_PATH\n",
    "from saiva.training.utils import load_config\n",
    "\n",
    "config = load_config(LOCAL_TRAINING_CONFIG_PATH)\n",
    "training_config = config.training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96f925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as pyo\n",
    "import plotly.io as pio\n",
    "import numpy as np\n",
    "pyo.init_notebook_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa976e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_path = Path('/data/processed')\n",
    "data_path = Path('/data/raw')\n",
    "\n",
    "CLIENT = \"+\".join([config.organization_id for config in training_config.organization_configs])\n",
    "\n",
    "EXPERIMENT_DATES = training_config.training_metadata.experiment_dates\n",
    "# starting training from day 31 so that cumsum window 2,7,14,30 are all initial correct.\n",
    "EXPERIMENT_DATES['train_start_date'] = str((pd.to_datetime(EXPERIMENT_DATES['train_start_date']) +  pd.DateOffset(days=30)).date())\n",
    "\n",
    "EXPERIMENT_DATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aefa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TYPE = MODEL_TYPE.lower()\n",
    "print('MODEL:', MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da47f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_target_3_day, _ = load_x_y_idens(processed_path, MODEL_TYPE, 'train')\n",
    "valid_x, valid_target_3_day, _ = load_x_y_idens(processed_path, MODEL_TYPE, 'valid')\n",
    "test_x, test_target_3_day, _ = load_x_y_idens(processed_path, MODEL_TYPE, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e5177d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_mode = isinstance(train_x, np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d247499",
   "metadata": {},
   "outputs": [],
   "source": [
    "if np_mode:\n",
    "    with open(processed_path/'cate_columns.pickle', 'rb') as f: cate_columns = pickle.load(f)\n",
    "    with open(processed_path/'feature_names.pickle', 'rb') as f: feature_names = pickle.load(f)\n",
    "    with open(processed_path/'pandas_categorical.pickle', 'rb') as f: pandas_categorical = pickle.load(f)\n",
    "    \n",
    "    train_x = pd.DataFrame(train_x, columns=feature_names)\n",
    "    valid_x = pd.DataFrame(valid_x, columns=feature_names)\n",
    "    test_x = pd.DataFrame(test_x, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4772c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x[f'target_3_day_{MODEL_TYPE}'] = train_target_3_day\n",
    "valid_x[f'target_3_day_{MODEL_TYPE}'] = valid_target_3_day\n",
    "test_x[f'target_3_day_{MODEL_TYPE}'] = test_target_3_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5e4f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_facilities_from_data(df=None, categorical_features=None, pandas_categorical=None):\n",
    "    if not df is None:\n",
    "        return list(df.facility.unique())\n",
    "    else:\n",
    "        return pandas_categorical[categorical_features.index('facility')]\n",
    "\n",
    "if np_mode:\n",
    "    facilities = [f.split('_')[1] for f in get_facilities_from_data(\n",
    "        categorical_features=cate_columns,\n",
    "        pandas_categorical=pandas_categorical\n",
    "    )]\n",
    "else:\n",
    "    facilities = [f.split('_')[1] for f in get_facilities_from_data(train_x)]\n",
    "\n",
    "client_df = pd.DataFrame(\n",
    "                    columns=[\"Client\", CLIENT], \n",
    "                    data=[['Facilities',','.join(facilities)],['Facility count',len(facilities)]]\n",
    "                 )\n",
    "\n",
    "def get_mm_distribution(df, dtype, start_date, end_date):\n",
    "    positive = df.query(f'target_3_day_{MODEL_TYPE} == 1').shape[0]\n",
    "    negative = df.query(f'target_3_day_{MODEL_TYPE} != 1').shape[0]\n",
    "    \n",
    "    n2p = round(negative/positive, 2)\n",
    "    total_patient_days = df.shape[0]\n",
    "    positive_percent = round((100 * positive) / total_patient_days, 2)\n",
    "    negative_percent = round((100 * negative) / total_patient_days, 2)\n",
    "    \n",
    "    return [total_patient_days, positive, negative, positive_percent, negative_percent, n2p, dtype, start_date, end_date]\n",
    "\n",
    "\n",
    "data_list = []\n",
    "data_list.append(get_mm_distribution(train_x, 'TRAIN', EXPERIMENT_DATES['train_start_date'], EXPERIMENT_DATES['train_end_date']))\n",
    "data_list.append(get_mm_distribution(valid_x, 'VALID', EXPERIMENT_DATES['validation_start_date'], EXPERIMENT_DATES['validation_end_date']))\n",
    "data_list.append(get_mm_distribution(test_x, 'TEST', EXPERIMENT_DATES['test_start_date'], EXPERIMENT_DATES['test_end_date']))\n",
    "\n",
    "\n",
    "dist_df = pd.DataFrame(\n",
    "                    columns=[\"Patient days\", \"Positive\", \"Negative\", \"Positive%\", \"Negative%\", \"N2P Ratio\",\"TYPE\",\"start_date\",\"end_date\"], \n",
    "                    data=data_list\n",
    "                 )\n",
    "dist_df['days'] = (pd.to_datetime(dist_df['end_date']) - pd.to_datetime(dist_df['start_date'])).dt.days\n",
    "\n",
    "\n",
    "dist_df.head()\n",
    "\n",
    "client_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a2e4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stay_length(staylength):\n",
    "    if staylength > 120:\n",
    "        return 120\n",
    "    else:\n",
    "        return staylength\n",
    "    \n",
    "def get_metrics_df(df, data_type):\n",
    "    # here each index indicates LOS and value indicates the count of transfer for that LOS\n",
    "    total = [0 for i in range(0,121)] \n",
    "    positive = [0 for i in range(0,121)] \n",
    "    negative = [0 for i in range(0,121)] \n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if pd.isnull(row['days_since_last_admission']): # very rare situation but still may happen\n",
    "            continue\n",
    "        j = int(get_stay_length(row['days_since_last_admission']))\n",
    "        total[j] += 1\n",
    "        if row[f'target_3_day_{MODEL_TYPE}'] == 1: \n",
    "            positive[j] += 1\n",
    "        elif row[f'target_3_day_{MODEL_TYPE}'] != 1:\n",
    "            negative[j] += 1\n",
    "        \n",
    "    \n",
    "    # create a dataframe from the above 3 lists\n",
    "    metric_df = pd.DataFrame ({\"ALL\": total, \"POSITIVE\": positive, \"NEGATIVE\": negative})\n",
    "\n",
    "    ## percentages at lengthofstay n\n",
    "    metric_df['positive_percent'] = ((metric_df['POSITIVE']/metric_df['ALL']) * 100).round(2)\n",
    "    metric_df['negative_percent'] = ((metric_df['NEGATIVE']/metric_df['ALL']) * 100).round(2)\n",
    "    \n",
    "    metric_df.columns = [data_type+'_'+col for col in metric_df.columns]\n",
    "    metric_df = metric_df.fillna(0)\n",
    "    \n",
    "    return metric_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d237bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "_df1 = get_metrics_df(train_x[['days_since_last_admission', f'target_3_day_{MODEL_TYPE}']], 'TRAIN')\n",
    "_df2 = get_metrics_df(valid_x[['days_since_last_admission', f'target_3_day_{MODEL_TYPE}']], 'VALID')\n",
    "_df3 = get_metrics_df(test_x[['days_since_last_admission', f'target_3_day_{MODEL_TYPE}']], 'TEST')\n",
    "\n",
    "final_df = pd.concat([_df1, _df2, _df3], axis=1)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f36f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_df[[\"TRAIN_POSITIVE_nor\",\"VALID_POSITIVE_nor\",\"TEST_POSITIVE_nor\"]] = MinMaxScaler(feature_range=(0, 100)).fit_transform(\n",
    "    final_df[[\"TRAIN_POSITIVE\",\"VALID_POSITIVE\",\"TEST_POSITIVE\"]]\n",
    ")\n",
    "\n",
    "final_df[[\"TRAIN_NEGATIVE_nor\",\"VALID_NEGATIVE_nor\",\"TEST_NEGATIVE_nor\"]] = MinMaxScaler(feature_range=(0, 100)).fit_transform(\n",
    "    final_df[[\"TRAIN_NEGATIVE\",\"VALID_NEGATIVE\",\"TEST_NEGATIVE\"]]\n",
    ")\n",
    "final_df.head()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269f98f8",
   "metadata": {},
   "source": [
    "## =========== Generate Graph to be pushed to MLFlow ==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83307d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bar_graph(final_df, pclass, data_type, selectedClass, client, colour):\n",
    "    _final_df = final_df.drop(final_df.tail(1).index)\n",
    "    # _final_df = final_df\n",
    "\n",
    "    fig = px.bar(\n",
    "        _final_df, \n",
    "        y=[selectedClass], \n",
    "        x=list(_final_df.index),\n",
    "        title=f'LOS Histogram for {pclass} patient days in {data_type} dataset for {client}',\n",
    "        labels={\n",
    "            'y':'Length Of Stay', \n",
    "            'caught_rth': 'LOS Count'\n",
    "        }, \n",
    "        color_discrete_sequence=[colour]\n",
    "    )\n",
    "    fig['layout']['xaxis']['title'] = \"Count\"\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def get_line_graph(final_df, selectedClasses, pclass, client):\n",
    "    _final_df = final_df.copy()\n",
    "    _final_df = final_df.drop(final_df.tail(1).index)\n",
    "\n",
    "    fig = px.line(\n",
    "        _final_df, \n",
    "        y=selectedClasses, \n",
    "        x=list(_final_df.index), \n",
    "        labels={\n",
    "            'x':'Length Of Stay', \n",
    "        }, \n",
    "        title=f'LOS Histogram for Normalised {pclass} patient days across Train, Valid & Test dataset for {client}',\n",
    "    )\n",
    "    fig['layout']['yaxis']['title'] = f\"{pclass} Patient day Normalised value between 0 to 100\"\n",
    "\n",
    "    return fig\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96629250",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(\n",
    "    rows=2, \n",
    "    cols=4, \n",
    "    subplot_titles=(\"POS Train\", \"POS Valid\", \"POS Test\", \"Normalised POS patient days\",\"NEG Train\", \"NEG Valid\", \"NEG Test\", \"Normalised NEG patient days\")\n",
    ")\n",
    "\n",
    "\n",
    "plot1 = get_bar_graph(final_df, 'Positive', 'Train', 'TRAIN_POSITIVE', CLIENT, 'blue')\n",
    "plot2 = get_bar_graph(final_df, 'Positive', 'Valid', 'VALID_POSITIVE', CLIENT, 'Red')\n",
    "plot3 = get_bar_graph(final_df, 'Positive', 'Test', 'TEST_POSITIVE', CLIENT, 'Green')\n",
    "\n",
    "plot4 = get_bar_graph(final_df, 'Negative', 'Train', 'TRAIN_NEGATIVE', CLIENT, 'blue')\n",
    "plot5 = get_bar_graph(final_df, 'Negative', 'Valid', 'VALID_NEGATIVE', CLIENT, 'Red')\n",
    "plot6 = get_bar_graph(final_df, 'Negative', 'Test', 'TEST_NEGATIVE', CLIENT, 'Green')\n",
    "\n",
    "plot7 = get_line_graph(final_df,[\"TRAIN_POSITIVE_nor\",\"VALID_POSITIVE_nor\",\"TEST_POSITIVE_nor\"] , 'Positive', CLIENT)\n",
    "plot8 = get_line_graph(final_df,[\"TRAIN_NEGATIVE_nor\",\"VALID_NEGATIVE_nor\",\"TEST_NEGATIVE_nor\"] , 'Negative', CLIENT)\n",
    "\n",
    "fig.add_trace(\n",
    "    plot1[\"data\"][0],\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    plot2[\"data\"][0],\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    plot3[\"data\"][0],\n",
    "    row=1, col=3\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    plot7[\"data\"][0],\n",
    "    row=1, col=4\n",
    ")\n",
    "fig.add_trace(\n",
    "    plot7[\"data\"][1],\n",
    "    row=1, col=4\n",
    ")\n",
    "fig.add_trace(\n",
    "    plot7[\"data\"][2],\n",
    "    row=1, col=4\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    plot4[\"data\"][0],\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    plot5[\"data\"][0],\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    plot6[\"data\"][0],\n",
    "    row=2, col=3\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    plot8[\"data\"][0],\n",
    "    row=2, col=4\n",
    ")\n",
    "fig.add_trace(\n",
    "    plot8[\"data\"][1],\n",
    "    row=2, col=4\n",
    ")\n",
    "fig.add_trace(\n",
    "    plot8[\"data\"][2],\n",
    "    row=2, col=4\n",
    ")\n",
    "\n",
    "fig.update_layout(height=900, \n",
    "                  width=1024, \n",
    "                  title_text=f\"LOS Histogram for patient days for {CLIENT}\")\n",
    "\n",
    "pio.write_image(fig, 'distribution_plot.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54c70b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution table \n",
    "\n",
    "layout = go.Layout(\n",
    "    autosize=False,\n",
    "    width=1000,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "layout2 = go.Layout(\n",
    "    autosize=False,\n",
    "    width=1000,\n",
    "    height=300,\n",
    "    title = \"* We discard first 30 days of training data to get correct cumsum 2/7/14/30 days calculations\",\n",
    ")\n",
    "\n",
    "\n",
    "fig1 = go.Figure(data=[go.Table(\n",
    "    header=dict(values=list(dist_df.columns),\n",
    "                fill_color='paleturquoise',\n",
    "                align='left'),\n",
    "    cells=dict(values=dist_df.transpose().values.tolist(),\n",
    "               fill_color='lavender',\n",
    "               align='left'))\n",
    "], layout=layout2)\n",
    "\n",
    "fig2 = go.Figure(data=[go.Table(\n",
    "    header=dict(values=list(client_df.columns),\n",
    "                fill_color='paleturquoise',\n",
    "                align='left'),\n",
    "    cells=dict(values=client_df.transpose().values.tolist(),\n",
    "               fill_color='lavender',\n",
    "               align='left'))\n",
    "], layout=layout)\n",
    "\n",
    "\n",
    "pio.write_image(fig1, 'distribution_table.png')\n",
    "pio.write_image(fig2, 'client_table.png')\n",
    "\n",
    "\n",
    "# fig1.show()\n",
    "# fig2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881e978e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the 2 images generated from above cells\n",
    "\n",
    "image0 = Image.open('./client_table.png','r')\n",
    "image1 = Image.open('./distribution_table.png','r')\n",
    "image2 = Image.open('./distribution_plot.png','r')\n",
    "\n",
    "image0 = image0.resize((image2.width, image0.height))\n",
    "image1 = image1.resize((image2.width, image1.height))\n",
    "dst = Image.new('RGB', (image1.width, image0.height + image1.height + image2.height), (250,250,250))\n",
    "dst.paste(image0, (0, 0))\n",
    "dst.paste(image1, (0, image0.height))\n",
    "dst.paste(image2, (0, image1.height+image0.height))\n",
    "dst.save(f\"distribution_{CLIENT}.png\",\"PNG\")\n",
    "dst.show()\n",
    "\n",
    "os.remove(\"distribution_plot.png\") \n",
    "os.remove(\"client_table.png\") \n",
    "os.remove(\"distribution_table.png\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c18d62d",
   "metadata": {},
   "source": [
    "## ===========================END======================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61d9722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac5702d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f369052",
   "metadata": {},
   "source": [
    "## Distribution of patients LOS in train / valid / test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3198f480",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_height = 750\n",
    "CLIENT = 'Vintage'\n",
    "data_type = 'Test'  # Test, Valid, Train\n",
    "pclass = 'Positive' # Negative, Positive\n",
    "selectedClass = 'TEST_POSITIVE' # TEST_NEGATIVE, TEST_POSITIVE, TRAIN_POSITIVE, TRAIN_NEGATIVE, VALID_POSITIVE, VALID_NEGATIVE\n",
    "allClass = 'TEST_ALL'  # VALID_ALL, TEST_ALL, TRAIN_ALL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a60904e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Experiment: Vintage-3-day-hosp-V6-hp-base-vintage')\n",
    "print(f'total {data_type} dataset size for {CLIENT}= ', final_df[allClass].sum())\n",
    "print(f'total {pclass} patient days in {data_type} data = ', final_df[selectedClass].sum())\n",
    "\n",
    "# Exclude last row ie. LOS=120\n",
    "_final_df = final_df.drop(final_df.tail(1).index)\n",
    "# _final_df = final_df\n",
    "\n",
    "fig = px.bar(\n",
    "    _final_df, \n",
    "    x=[selectedClass], \n",
    "    y=list(_final_df.index),\n",
    "    height=graph_height, \n",
    "    orientation='h',\n",
    "    title=f'LOS Histogram for {pclass} patient days in {data_type} dataset for {CLIENT}',\n",
    "    labels={\n",
    "        'y':'Length Of Stay', \n",
    "        'caught_rth': 'LOS Count'\n",
    "    }, \n",
    "    color_discrete_sequence=['green']\n",
    ")\n",
    "fig['layout']['yaxis']['autorange'] = \"reversed\"\n",
    "fig['layout']['xaxis']['title'] = \"Count\"\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ecf3d2",
   "metadata": {},
   "source": [
    "## ================ LOS Histogram for Normalised ================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f10ef65",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_height = 750\n",
    "CLIENT = 'Vintage'\n",
    "pclass = 'Negative' # Negative, Positive\n",
    "selectedClasses = [\"TRAIN_NEGATIVE_nor\",\"VALID_NEGATIVE_nor\",\"TEST_NEGATIVE_nor\"]\n",
    "    # [\"TRAIN_NEGATIVE_nor\",\"VALID_NEGATIVE_nor\",\"TEST_NEGATIVE_nor\"]\n",
    "    # [\"TRAIN_POSITIVE_nor\",\"VALID_POSITIVE_nor\",\"TEST_POSITIVE_nor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c214e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_final_df = final_df\n",
    "_final_df = final_df.drop(final_df.tail(1).index)\n",
    "\n",
    "fig = px.line(\n",
    "    _final_df, \n",
    "    y=selectedClasses, \n",
    "    x=list(_final_df.index), \n",
    "    labels={\n",
    "        'x':'Length Of Stay', \n",
    "    }, \n",
    "    height=750, \n",
    "    title=f'LOS Histogram for Normalised {pclass} patient days across Train, Valid & Test dataset for {CLIENT}',\n",
    ")\n",
    "fig['layout']['yaxis']['title'] = f\"{pclass} Patient day Normalised value between 0 to 100\"\n",
    "# fig['layout']['yaxis']['tickformat'] = ',.0%'\n",
    "# fig['layout']['yaxis']['range'] = [0,1]\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d59e4a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
