{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/src')\n",
    "import pickle\n",
    "from data_models import BaseModel\n",
    "from shared.load_raw_data import join_tables\n",
    "from pathlib import Path\n",
    "import boto3\n",
    "from urllib.parse import urlparse\n",
    "import pandas as pd\n",
    "\n",
    "import shap\n",
    "import re\n",
    "from shared.explanations_config import exp_dictionary\n",
    "from shared.generate_base_features import sorting_and_deduping_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_date = '2020-05-15'\n",
    "client = 'avante'\n",
    "facilityid = '10'\n",
    "s3_folder = 'explanations/run1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_list = ['master_patient_lookup','patient_census','patient_rehosps',\n",
    "              'patient_progress_notes','patient_diagnosis','patient_vitals','patient_lab_results',\n",
    "             'patient_meds','patient_orders','patient_alerts','patient_demographics']\n",
    "raw_data_dict = {}\n",
    "for table in table_list:\n",
    "    print(f\"reading {table}\")\n",
    "    raw_data_dict[table] = pd.read_parquet(\n",
    "                    f\"s3://saiva-dev-data-bucket/data/avante/{prediction_date}/{facilityid}/{s3_folder}/{table}.parquet\"\n",
    "                )\n",
    "# joing with masterpatientid\n",
    "raw_data_dict = join_tables(raw_data_dict)\n",
    "# sort and dedup raw data\n",
    "sorting_and_deduping_dataframes(raw_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modelid = '4e78363600a14e65866d8c1ef7ab28fe'\n",
    "with open(f\"/data/models/{modelid}/artifacts/{modelid}.pickle\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_x =     pd.read_parquet(f\"s3://saiva-dev-data-bucket/data/avante/{prediction_date}/{facilityid}/{s3_folder}/finalx_output.parquet\")\n",
    "final_idens = pd.read_parquet(f\"s3://saiva-dev-data-bucket/data/avante/{prediction_date}/{facilityid}/{s3_folder}/finalidens_output.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_idens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3client = boto3.client('s3')\n",
    "# response = s3client.get_object(Bucket='saiva-playground', Key=f'explanations_playground/{client}/result_dict.pickle')\n",
    "# body = response['Body'].read()\n",
    "# raw_data_dict = pickle.loads(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_dict['patient_rehosps'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_medications(raw_df_dict):\n",
    "    patient_meds = raw_df_dict['patient_meds']\n",
    "    patient_meds['only_med_name'] = patient_meds['orderdescription'].str.replace(r' Tablet.*| Liquid.*| Powder.*| Packet.*| Solution.*| Suspension.*','')\n",
    "    patient_meds = patient_meds.sort_values(by='orderdate', ascending = True)\n",
    "    return patient_meds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_diet_and_diagnostic_orders(raw_df_dict):\n",
    "    patient_orders = raw_df_dict['patient_orders']\n",
    "    patient_orders2 = patient_orders.sort_values(by='orderdate', ascending = True)\n",
    "    return patient_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_alerts(raw_df_dict):\n",
    "    patient_alerts = raw_df_dict['patient_alerts']\n",
    "    patient_alerts['createddt'] = patient_alerts['createddate'].dt.date\n",
    "    patient_alerts = patient_alerts.sort_values(by='createddate', ascending = True)\n",
    "    return patient_alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_diagnosis(raw_df_dict):\n",
    "    patient_diagnosis = raw_df_dict['patient_diagnosis']\n",
    "    patient_diagnosis = patient_diagnosis.sort_values(by='onsetdate', ascending = True)\n",
    "    return patient_diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_vitals(raw_df_dict):\n",
    "    patient_vitals = raw_df_dict['patient_vitals']\n",
    "    patient_vitals['orderdt'] = patient_vitals['date'].dt.date\n",
    "    patient_vitals = patient_vitals.sort_values(by='date', ascending = True)\n",
    "    return patient_vitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_rehosps(raw_df_dict):\n",
    "    patient_rehosps = raw_df_dict['patient_rehosps']\n",
    "    patient_rehosps = patient_rehosps.sort_values(by='dateoftransfer', ascending = True)\n",
    "    return patient_rehosps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_labs(raw_df_dict):\n",
    "    patient_labs = raw_df_dict['patient_lab_results']\n",
    "    patient_labs['resultdt'] = patient_labs['resultdate'].dt.date\n",
    "    patient_labs = patient_labs.sort_values(by='resultdate', ascending = True)\n",
    "    return patient_labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_raw_data(raw_df_dict):\n",
    "    ret_dict = {}\n",
    "    \n",
    "    ret_dict['patient_meds'] = process_medications(raw_df_dict)\n",
    "    ret_dict['patient_orders'] = process_diet_and_diagnostic_orders(raw_df_dict)\n",
    "    ret_dict['patient_alerts'] = process_alerts(raw_df_dict)\n",
    "    ret_dict['patient_diagnosis'] = process_diagnosis(raw_df_dict)\n",
    "    ret_dict['patient_vitals'] = process_vitals(raw_df_dict)\n",
    "    ret_dict['patient_rehosps'] = process_rehosps(raw_df_dict)\n",
    "    ret_dict['patient_lab_results'] = process_labs(raw_df_dict)\n",
    "    \n",
    "    return ret_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_attributions(numeric_attributions):\n",
    "    sorted_numeric_attributions = numeric_attributions.sort_values('attribution_score', ascending=False)\n",
    "    \n",
    "    # use this dict to combine attributions.  For example, cumsum_all_med_Heparain and cumsum_7_day_Heparin,\n",
    "    # become cumsum_med_Heparin and then get deduped into one row and the attribution percentages get added\n",
    "    # together\n",
    "    feature_mapping_dict = {\n",
    "        'cumsum_all_med_' : 'cumsum_med_',\n",
    "        r'cumsum_\\d+_day_med_': 'cumsum_med_',\n",
    "        'cumsum_all_order_': 'cumsum_order_',\n",
    "        r'cumsum_\\d+_day_order_': 'cumsum_order_',\n",
    "        'cumsum_all_alert_': 'cumsum_alert_',\n",
    "        r'cumsum_\\d+_day_alert_': 'cumsum_alert_',\n",
    "        'cumsum_all_dx_': 'cumsum_dx_',\n",
    "        r'cumsum_\\d+_day_dx_': 'cumsum_dx_',\n",
    "        'cumsum_all_labs_': 'cumsum_labs_',\n",
    "        r'cumsum_\\d+_day_labs_': 'cumsum_labs_',\n",
    "    }\n",
    "    \n",
    "    type_mapping_dict = {\n",
    "        r'^cumsum_all_med_.*' : 'Medication',\n",
    "        r'^cumsum_\\d+_day_med_.*': 'Medication',\n",
    "        r'^na_indictator_med_.*': 'Medication',\n",
    "        r'^cumsum.*diagnostic_orders': 'Diagnostic Order',\n",
    "        r'^na_indictator_order_.*diagnostic_orders': 'Diagnostic Order',\n",
    "        r'^cumsum_all_order_.*': 'Diet Order',\n",
    "        r'^cumsum_\\d+_day_order_.*': 'Diet Order',\n",
    "        r'^na_indictator_order_.*': 'Diet Order',       \n",
    "        r'^cumsum_all_alert_.*': 'Alert',\n",
    "        r'^cumsum_\\d+_day_alert_.*': 'Alert',\n",
    "        r'^na_indictator_alert_.*': 'Alert',\n",
    "        r'^cumsum_all_dx_.*' : 'Diagnosis',\n",
    "        r'^cumsum_\\d+_day_dx_.*': 'Diagnosis',\n",
    "        r'^na_indictator_dx_.*': 'Diagnosis',\n",
    "        r'^cumsum_all_labs_.*' : 'Lab',\n",
    "        r'^cumsum_\\d+_day_labs_.*': 'Lab',\n",
    "        r'^na_indictator_labs_.*': 'Lab',\n",
    "        r'^vtl_.*': 'Vital',\n",
    "        r'^rol_avg_\\d+_day_vtl_.*': 'Vital',\n",
    "        r'^rol_std_\\d+_day_vtl_.*': 'Vital',\n",
    "        r'^diff_\\d+_day_vtl_.*': 'Vital',\n",
    "        r'^na_indictator_vtl_.*': 'Vital',\n",
    "        r'^demo_.*': 'Demographic',\n",
    "        r'^na_indictator_religion$': 'Demographic',\n",
    "        r'^na_indictator_education$': 'Demographic',\n",
    "        r'^na_indictator_race$': 'Demographic',\n",
    "        r'^na_indictator_citizenship$': 'Demographic',\n",
    "        r'^na_indictator_state$': 'Demographic',\n",
    "        r'^dateofbirth_.*': 'Demographic',\n",
    "        r'^e_pn_.*': 'Progress Note',\n",
    "        r'^e_eMar_.*': 'eMar',\n",
    "        r'^hosp_count.*': 'patient_rehosps',\n",
    "        r'^hosp_days.*': 'patient_rehosps',\n",
    "        r'^na_indictator_hosp_.*': 'patient_rehosps',\n",
    "        r'^censusdate_.*': 'patient_census',\n",
    "        r'^na_indictator_roomratetypedescription$': 'patient_census',\n",
    "        r'^na_indictator_carelevelcode$': 'patient_census',\n",
    "        r'^na_indictator_beddescription$': 'patient_census',\n",
    "    }\n",
    "\n",
    "    sorted_numeric_attributions['human_readable_name'] = ''\n",
    "    sorted_numeric_attributions['mapping_status'] = 'NOT_MAPPED'\n",
    "    sorted_numeric_attributions['mapped_feature'] = sorted_numeric_attributions['feature'].replace(feature_mapping_dict, regex=True)\n",
    "    sorted_numeric_attributions['feature_type'] = sorted_numeric_attributions['feature'].replace(type_mapping_dict, regex=True)\n",
    "    sorted_numeric_attributions['day_count'] = sorted_numeric_attributions['feature'].str.extract(r'_(\\d+)_day')\n",
    "    sorted_numeric_attributions['all_time'] = sorted_numeric_attributions['feature'].str.extract(r'_(all)_')\n",
    "    sum_attributions = sorted_numeric_attributions['attribution_score'].sum()\n",
    "    sorted_numeric_attributions['attribution_percent'] = sorted_numeric_attributions['attribution_score']/sum_attributions*100.0\n",
    "    assert(abs(100.0 - sorted_numeric_attributions['attribution_percent'].sum()) <= 0.0001)\n",
    "    \n",
    "    attribution_df = sorted_numeric_attributions.groupby(['mapped_feature'])['attribution_score', 'attribution_percent'].sum()\n",
    "    attribution_df = attribution_df.rename(columns={'attribution_score': 'sum_attribution_score',\n",
    "                                                    'attribution_percent': 'sum_attribution_percent'})\n",
    "    sorted_numeric_attributions = sorted_numeric_attributions.merge(attribution_df, how='left', on=['mapped_feature'])\n",
    "    sorted_numeric_attributions.sort_values(by=['day_count'], inplace=True, ascending=True)\n",
    "    sorted_numeric_attributions_only_diagnosis = sorted_numeric_attributions[sorted_numeric_attributions['feature_type']=='Diagnosis']\n",
    "    sorted_numeric_attributions = sorted_numeric_attributions[sorted_numeric_attributions['feature_type'] != 'Diagnosis']\n",
    "    deduped_numeric_attributions = sorted_numeric_attributions.drop_duplicates(subset='mapped_feature', keep='first').copy()\n",
    "    deduped_numeric_attributions = pd.concat([deduped_numeric_attributions,sorted_numeric_attributions_only_diagnosis])\n",
    "    deduped_numeric_attributions['cumsum_attribution_percent'] = deduped_numeric_attributions['sum_attribution_percent'].cumsum()\n",
    "    return deduped_numeric_attributions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns 0 if day_count was not present\n",
    "def get_day_count(attribution_row):\n",
    "    day_count = 0\n",
    "    if pd.notna(attribution_row['day_count']):\n",
    "        day_count = int(attribution_row['day_count'])\n",
    "    return day_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a string like \"2 Alerts for \"Answer on bowel control\" in Last 14 Days\"\n",
    "#                   or \"3 Orders for Sympathomimetics in EHR System\"\n",
    "#                   or \"1 Dispense Alert in Last 7 Days\"\n",
    "def get_leading_reason_string(event_count_str, day_count, all_time_str, \n",
    "                              singular_form, plural_form, match_name='', alert_type_str=''):\n",
    "    event_count = int(event_count_str)\n",
    "    \n",
    "    ret_str = f'{event_count}'\n",
    "    if alert_type_str != '':\n",
    "        ret_str += f' {alert_type_str}'\n",
    "    if (event_count == 1):\n",
    "        ret_str += f' {singular_form}'\n",
    "    else:\n",
    "        ret_str += f' {plural_form}'\n",
    "    if match_name != '':\n",
    "        ret_str += f' for \"{match_name}\"'\n",
    "    \n",
    "    # now add 'in EHR System' or 'in n days'\n",
    "    if all_time_str == 'all':\n",
    "        ret_str += ' in EHR System.'\n",
    "    elif day_count != 0:\n",
    "        ret_str += f' in last {day_count} days.'\n",
    "    \n",
    "    return ret_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a string like \" (Last Alert on 2019-09-10)\"\"\n",
    "#                   or \" (Last Order: \"Lovenox\" on 2019-03-21)\"\"\n",
    "def get_last_detail_string(noun, last_details_on, last_details=''):\n",
    "    ret_str = f' Last {noun}'\n",
    "    if last_details != '':\n",
    "        ret_str += f': \"{last_details}\"'\n",
    "    ret_str += f' on {last_details_on:%m-%d-%Y}.'\n",
    "#     print(ret_str)\n",
    "    return ret_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_alert_type(alert_type):\n",
    "    if alert_type == 'allergy':\n",
    "        alert_type_char = 'A'\n",
    "        alert_type_string = 'Allergy'\n",
    "    elif alert_type == 'dispense':\n",
    "        alert_type_char = 'D'\n",
    "        alert_type_string = 'Dispense'\n",
    "    elif alert_type == 'order':\n",
    "        alert_type_char = 'O'\n",
    "        alert_type_string = 'Order'\n",
    "    else:\n",
    "        assert('unexpected alert_count_indicator')\n",
    "    return (alert_type_char, alert_type_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alert_mapper(alert_attribution, processed_df_dict, mpid_to_use, date_to_use):\n",
    "    alert_data = processed_df_dict['patient_alerts']\n",
    "    human_readable_name = ''\n",
    "    mapping_status = 'NOT_MAPPED'\n",
    "    if (alert_attribution['mapped_feature'].startswith('cumsum_alert_indicator_') or\n",
    "        alert_attribution['mapped_feature'].startswith('cumsum_alert_count_indicator_')) \\\n",
    "            and (alert_attribution['feature_value'] == 0):\n",
    "        # if feature_value is 0 for cumsum features, it means that no alerts exist for that med feature\n",
    "        mapping_status = 'NOT_RELEVANT'\n",
    "    elif alert_attribution['mapped_feature'].startswith('cumsum_alert_indicator_'):\n",
    "        alert_name = alert_attribution['mapped_feature'].replace('cumsum_alert_indicator_', '')\n",
    "        # print(\"alert_name is {}\".format(alert_name))\n",
    "        alert_matches = alert_data[(alert_data.masterpatientid == mpid_to_use) &\n",
    "                                   (alert_data.alertdescription == alert_name)]\n",
    "        day_count = get_day_count(alert_attribution)\n",
    "        if day_count != 0:\n",
    "            # print(\"day_count={}\".format(day_count))\n",
    "            alert_matches = alert_matches[alert_matches.createddate >= (date_to_use - pd.to_timedelta(day_count, unit='d'))]\n",
    "        \n",
    "        # now get the most recent alert (since it is already sorted by created_date)\n",
    "        alert_reason = alert_matches.tail(1).copy()\n",
    "        if len(alert_reason) > 0:\n",
    "            human_readable_name = get_leading_reason_string(alert_attribution['feature_value'], day_count,\n",
    "                                                            all_time_str='', singular_form=\"Alert\",\n",
    "                                                            plural_form=\"Alerts\", match_name= alert_name)\n",
    "                \n",
    "            human_readable_name += get_last_detail_string('Alert', alert_reason.iloc[0]['createddt'])\n",
    "            if day_count in exp_dictionary['Alert_Indicator'].keys() and \\\n",
    "                    alert_name.lower() in exp_dictionary['Alert_Indicator'][day_count]:\n",
    "                mapping_status = 'MAPPED'\n",
    "            else:\n",
    "                mapping_status = 'DATA_FOUND'\n",
    "            \n",
    "        else:\n",
    "            mapping_status = 'DATA_NOT_FOUND'\n",
    "    elif alert_attribution['mapped_feature'].startswith('cumsum_alert_count_indicator_'):\n",
    "        alert_type = alert_attribution['mapped_feature'].replace('cumsum_alert_count_indicator_', '')\n",
    "        (alert_type_char, alert_type_string) = map_alert_type(alert_type)\n",
    "        feature_value = alert_attribution['feature_value']\n",
    "        # print(f'found {alert_type_string}:{alert_type_char} with feature value {feature_value}')\n",
    "        alert_matches = alert_data[(alert_data.masterpatientid == mpid_to_use) &\n",
    "                                   (alert_data.triggereditemtype == alert_type_char)]\n",
    "        day_count = get_day_count(alert_attribution)\n",
    "        if day_count != 0:\n",
    "            # print(\"day_count={}\".format(day_count))\n",
    "            alert_matches = alert_matches[alert_matches.createddate >= (date_to_use - pd.to_timedelta(day_count, unit='d'))]\n",
    "        \n",
    "        # now get the most recent alert (since it is already sorted by created_date)\n",
    "        alert_reason = alert_matches.tail(1).copy()\n",
    "        if len(alert_reason) > 0:\n",
    "            human_readable_name = get_leading_reason_string(alert_attribution['feature_value'], day_count,\n",
    "                                                            all_time_str='', singular_form=\"Alert\",\n",
    "                                                            plural_form=\"Alerts\", alert_type_str=alert_type_string)\n",
    "            human_readable_name += get_last_detail_string('Alert', alert_reason.iloc[0]['createddt'],\n",
    "                                                          alert_reason.iloc[0]['alertdescription'].replace('\\n',' '))\n",
    "            if day_count in exp_dictionary['Alert_Count_Indicator'].keys() and \\\n",
    "                    alert_type_string.lower() in exp_dictionary['Alert_Count_Indicator'][day_count]:\n",
    "                mapping_status = 'MAPPED'\n",
    "            else:\n",
    "                mapping_status = 'DATA_FOUND'\n",
    "\n",
    "        else:\n",
    "            mapping_status = 'DATA_NOT_FOUND'\n",
    "        \n",
    "    return pd.Series([human_readable_name, mapping_status], index=['a', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def med_mapper(med_attribution, processed_df_dict, mpid_to_use, date_to_use):\n",
    "    med_data = processed_df_dict['patient_meds']\n",
    "    human_readable_name = ''\n",
    "    mapping_status = 'NOT_MAPPED'\n",
    "    if (med_attribution['mapped_feature'].startswith('cumsum_med_')) and (med_attribution['feature_value'] == 0):\n",
    "        # if feature_value is 0 for cumsum features, it means that no meds exist for that med feature\n",
    "        mapping_status = 'NOT_RELEVANT'\n",
    "    elif med_attribution['mapped_feature'].startswith('cumsum_med_'):\n",
    "        # med does exist\n",
    "        med_grouping_name = med_attribution['mapped_feature'].replace('cumsum_med_', '')\n",
    "        # print(\"med_grouping_name is {}\".format(med_grouping_name))\n",
    "        med_matches = med_data[(med_data.masterpatientid == mpid_to_use) &\n",
    "                                (med_data.gpisubclassdescription == med_grouping_name)]\n",
    "        # if not found in subclassdescription, search the gpiclass instead (that is how the feature is defined)\n",
    "        if (len(med_matches) == 0):\n",
    "            med_matches = med_data[(med_data.masterpatientid == mpid_to_use) &\n",
    "                                (med_data.gpiclass == med_grouping_name)]\n",
    "        day_count = get_day_count(med_attribution)\n",
    "        if day_count != 0:\n",
    "            # print(\"day_count={}\".format(day_count))\n",
    "            med_matches = med_matches[med_matches.orderdate >= (date_to_use - pd.to_timedelta(day_count, unit='d'))]\n",
    "        \n",
    "        # now get the most recent med (since it is already sorted by order_date)\n",
    "        med_reason = med_matches.tail(1).copy().reset_index(drop=True)\n",
    "        if (len(med_reason) > 0):\n",
    "            med_name = med_reason.iloc[0]['only_med_name']\n",
    "            human_readable_name = get_leading_reason_string(med_attribution['feature_value'], day_count, '',\n",
    "                                                 \"Order\", \"Orders\", match_name=med_name)\n",
    "            human_readable_name += get_last_detail_string('Order', med_reason.iloc[0]['orderdate'],'')\n",
    "            if day_count in exp_dictionary['Patient_Meds'].keys() and \\\n",
    "                    med_grouping_name.lower() in exp_dictionary['Patient_Meds'][day_count] and med_attribution['feature_value']:\n",
    "                mapping_status = 'MAPPED'\n",
    "            else:\n",
    "                mapping_status = 'DATA_FOUND'\n",
    "        else:\n",
    "            mapping_status = 'DATA_NOT_FOUND'\n",
    "    return pd.Series([human_readable_name, mapping_status], index=['a', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lab_mapper(lab_attribution, processed_df_dict, mpid_to_use, date_to_use):\n",
    "    lab_data = processed_df_dict['patient_lab_results']\n",
    "    human_readable_name = ''\n",
    "    mapping_status = 'NOT_MAPPED'\n",
    "    if (lab_attribution['mapped_feature'].startswith('cumsum_labs_')) and (lab_attribution['feature_value'] == 0):\n",
    "        # if feature_value is 0 for cumsum features, it means that no labs exist for that lab feature\n",
    "        mapping_status = 'NOT_RELEVANT'\n",
    "    elif (lab_attribution['mapped_feature'].startswith('cumsum_labs_')):\n",
    "        # lab does exist\n",
    "        profile_and_abnormality = lab_attribution['mapped_feature'].replace('cumsum_labs__', '')\n",
    "        profile, abnormality = profile_and_abnormality.split('__')\n",
    "        profile = profile.replace('_', ' ')\n",
    "        abnormality = abnormality.replace('_', ' ')\n",
    "        # print(f\\\"profile is {profile} and abnormality is {abnormality}\\\")\n",
    "        lab_matches = lab_data[(lab_data.masterpatientid == mpid_to_use) &\n",
    "                                (lab_data.profiledescription == profile) &\n",
    "                                (lab_data.abnormalitydescription == abnormality)]\n",
    "        day_count = get_day_count(lab_attribution)\n",
    "        if day_count != 0:\n",
    "            # print(\\\"day_count={}\\\".format(day_count))\n",
    "            lab_matches = lab_matches[lab_matches.resultdate >= (date_to_use - pd.to_timedelta(day_count, unit='d'))]\n",
    "        # now get the most recent lab (since it is already sorted by order_date)\n",
    "        lab_reason = lab_matches.tail(1).copy().reset_index(drop=True)\n",
    "        if (len(lab_reason) > 0):           \n",
    "            human_readable_name = get_leading_reason_string(lab_attribution['feature_value'], day_count, lab_attribution['all_time'],\n",
    "                                                    \"Lab\", \"Labs\", match_name=profile)\n",
    "            human_readable_name += f\" Last lab result was {lab_reason.iloc[0]['abnormalitydescription']} on {lab_reason.iloc[0]['resultdate']:%m-%d-%Y}\"\n",
    "            if day_count != 0:\n",
    "                mapping_status = 'MAPPED'\n",
    "            else:\n",
    "                mapping_status = 'DATA_FOUND'\n",
    "        else:\n",
    "            mapping_status = 'DATA_NOT_FOUND'\n",
    "    return pd.Series([human_readable_name, mapping_status], index=['a', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diet_order_mapper(diet_attribution, processed_df_dict, mpid_to_use, date_to_use):\n",
    "    order_data = processed_df_dict['patient_orders']\n",
    "    human_readable_name = ''\n",
    "    mapping_status = 'NOT_MAPPED'\n",
    "    if (diet_attribution['mapped_feature'].startswith('cumsum_order_')) and (diet_attribution['feature_value'] == 0):\n",
    "        mapping_status = 'NOT_RELEVANT'\n",
    "    elif diet_attribution['mapped_feature'].startswith('cumsum_order_'):\n",
    "        diet_name = diet_attribution['mapped_feature'].replace('cumsum_order_', '')\n",
    "        # print(\"diet_name is {}\".format(diet_name))\n",
    "        diet_matches = order_data[(order_data.masterpatientid == mpid_to_use) & \n",
    "                                  ((order_data.diettype == diet_name) | (order_data.diettexture == diet_name) | \n",
    "                                   (order_data.dietsupplement == diet_name))]\n",
    "        day_count = get_day_count(diet_attribution)\n",
    "        if day_count != 0:\n",
    "            # print(\"day_count={}\".format(day_count))\n",
    "            diet_matches = diet_matches[diet_matches.orderdate >= (date_to_use - pd.to_timedelta(day_count, unit='d'))]\n",
    "        \n",
    "        # now get the most recent order (since it is already sorted by order_date)\n",
    "        diet_reason = diet_matches.tail(1).copy().reset_index(drop=True)\n",
    "        if (len(diet_reason) > 0):\n",
    "            human_readable_name = f'Diet order for {diet_name} in last {day_count} days (on {diet_reason.iloc[0][\"orderdate\"].date():%m-%d-%Y}).'\n",
    "            if day_count in exp_dictionary['Diet_Order'].keys() and diet_name.lower() in exp_dictionary['Diet_Order'][day_count]:\n",
    "                mapping_status = 'MAPPED'\n",
    "            else:\n",
    "                mapping_status = 'DATA_FOUND'\n",
    "        else:\n",
    "            mapping_status = 'DATA_NOT_FOUND'\n",
    "    return pd.Series([human_readable_name, mapping_status], index=['a', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnostic_order_mapper(diag_attribution, processed_df_dict, mpid_to_use, date_to_use):\n",
    "    order_data = processed_df_dict['patient_orders']\n",
    "    human_readable_name = ''\n",
    "    mapping_status = 'NOT_MAPPED'\n",
    "    if (diag_attribution['mapped_feature'].startswith('cumsum_order_')) and (diag_attribution['feature_value'] == 0):\n",
    "        mapping_status = 'NOT_RELEVANT'\n",
    "\n",
    "    elif diag_attribution['mapped_feature'].startswith('cumsum_order_'):\n",
    "        diag_matches = order_data[(order_data.masterpatientid == mpid_to_use) & \n",
    "                                  (order_data.ordercategory == 'Diagnostic')]\n",
    "        day_count = get_day_count(diag_attribution)\n",
    "        if day_count != 0:\n",
    "            # print(\"day_count={}\".format(day_count))\n",
    "            diag_matches = diag_matches[diag_matches.orderdate >= (date_to_use - pd.to_timedelta(day_count, unit='d'))]\n",
    "        \n",
    "        # now get the most recent order (since it is already sorted by order_date)\n",
    "        diag_reason = diag_matches.tail(1).copy().reset_index(drop=True)\n",
    "        \n",
    "        if (len(diag_reason) > 0):\n",
    "            human_readable_name = get_leading_reason_string(diag_attribution['feature_value'], day_count,\n",
    "                                                                all_time_str='', singular_form=\"Diagnostic Order\", \n",
    "                                                                plural_form=\"Diagnostic Orders\")\n",
    "            human_readable_name += get_last_detail_string('Order', diag_reason.iloc[0]['orderdate'].date(),\n",
    "                                                          diag_reason.iloc[0]['orderdescription'].replace('\\n',' '))\n",
    "            if day_count in exp_dictionary['Diagnostic_Order']:\n",
    "                mapping_status = 'MAPPED' \n",
    "            else:\n",
    "                mapping_status = 'DATA_FOUND'      \n",
    "        else:\n",
    "            mapping_status = 'DATA_NOT_FOUND'\n",
    "    return pd.Series([human_readable_name, mapping_status], index=['a', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dx_mapper(dx_attribution, processed_df_dict, mpid_to_use, date_to_use):\n",
    "    diag_data = processed_df_dict['patient_diagnosis']\n",
    "    human_readable_name = ''\n",
    "    mapping_status = 'NOT_MAPPED'\n",
    "    if (dx_attribution['mapped_feature'].startswith('cumsum_dx_')) and (dx_attribution['feature_value'] == 0):\n",
    "        mapping_status = 'NOT_RELEVANT'\n",
    "\n",
    "    elif dx_attribution['mapped_feature'].startswith('cumsum_dx_'):\n",
    "        diag_label = dx_attribution['mapped_feature'].replace('cumsum_dx_', '')\n",
    "        \n",
    "        diag_matches = diag_data[(diag_data.masterpatientid == mpid_to_use) & \n",
    "                                  (diag_data.ccs_label == diag_label)]\n",
    "        day_count = get_day_count(dx_attribution)\n",
    "        if day_count != 0:\n",
    "            # print(\"day_count={}\".format(day_count))\n",
    "            diag_matches = diag_matches[diag_matches.onsetdate >= (date_to_use - pd.to_timedelta(day_count, unit='d'))]        \n",
    "        # now get the most recent order (since it is already sorted by onset_date)\n",
    "        diag_reason = diag_matches.tail(1).copy().reset_index(drop=True)\n",
    "        \n",
    "        if (len(diag_reason) > 0):\n",
    "            human_readable_name = f\"Diagnosis of {diag_reason.iloc[0]['diagnosiscode']} : {diag_reason.iloc[0]['diagnosisdesc']} recorded on {diag_reason.iloc[0]['onsetdate']:%m-%d-%Y}.\"\n",
    "            if day_count in exp_dictionary['Patient_Diagnosis'].keys() and diag_label.lower() in exp_dictionary['Patient_Diagnosis'][\n",
    "                day_count]:\n",
    "                mapping_status = 'MAPPED'\n",
    "            elif (dx_attribution['all_time']=='all') and \\\n",
    "                    (any(diag_all_string in diag_label.lower() for diag_all_string in exp_dictionary['Patient_Diagnosis']['all'])):\n",
    "                mapping_status = 'MAPPED'\n",
    "            else:\n",
    "                mapping_status = 'DATA FOUND'\n",
    "        else:\n",
    "            mapping_status = 'DATA_NOT_FOUND'\n",
    "    return pd.Series([human_readable_name, mapping_status], index=['a', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def format_float_str(float_val):\n",
    "    return '{:.2f}'.format(float_val).rstrip('0').rstrip('.')\n",
    "\n",
    "def vital_mapper(vital_attribution, processed_df_dict, mpid_to_use, date_to_use):\n",
    "    aggfunc_mapping = {'min': 'Minimum',\n",
    "                       'max': 'Maximum',\n",
    "                       'std': 'Variation',\n",
    "                       'median': 'Average'}\n",
    "    vital_data = processed_df_dict['patient_vitals']\n",
    "    human_readable_name = ''\n",
    "    mapping_status = 'NOT_MAPPED'\n",
    "\n",
    "    # e.g vtl_max_Pain Level\n",
    "    daily_match = re.match(r'^vtl_(max|min|median|std)_(.*)$', vital_attribution['mapped_feature'])\n",
    "    # e.g. diff_7_day_vtl_min_O2 sats\n",
    "    diff_match = re.match(r'^diff_\\d+_day_vtl_(max|min|median|std)_(.*)$', vital_attribution['mapped_feature'])\n",
    "    # e.g. rol_avg_7_day_vtl_std_Pain Level\n",
    "    rol_avg_match = re.match(r'^rol_avg_\\d+_day_vtl_(max|min|median|std)_(.*)$', vital_attribution['mapped_feature'])\n",
    "    # e.g rol_std_14_day_vtl_max_Pain Level\n",
    "    rol_std_match = re.match(r'^rol_std_\\d+_day_vtl_(max|min|median|std)_(.*)$', vital_attribution['mapped_feature'])\n",
    "    if daily_match:\n",
    "        aggfunc = daily_match.groups()[0]\n",
    "        vital_type = daily_match.groups()[1]\n",
    "        # print(f\"matched {aggfunc} and {vital_type}\")\n",
    "\n",
    "        vital_matches = vital_data[(vital_data.masterpatientid == mpid_to_use) &\n",
    "                                   (vital_data.vitalsdescription == vital_type) &\n",
    "                                   (vital_data.value == vital_attribution['feature_value'])]\n",
    "\n",
    "        day_count = 1\n",
    "        vital_matches = vital_matches[vital_matches.date >= (date_to_use - pd.to_timedelta(day_count, unit='d'))]\n",
    "\n",
    "        if (len(vital_matches) > 0):\n",
    "            # to get feature_value with trailing 0s and . elimiated\n",
    "            feature_value_str = format_float_str(vital_attribution['feature_value'])\n",
    "            date_to_use_dt = date_to_use.date()\n",
    "            aggregation = aggfunc_mapping[aggfunc]\n",
    "            vitals_display_date = vital_matches.iloc[0]['date']\n",
    "            human_readable_name = f\"{aggregation} {vital_type}: {feature_value_str} on {vitals_display_date:%m-%d-%Y} at {vitals_display_date:%H:%M}.\"\n",
    "            #vitals - pulse\n",
    "            if aggregation=='Maximum' and vital_type=='Pulse':\n",
    "                human_readable_name = f\"Maximum recorded pulse {vital_attribution['feature_value']} on {vitals_display_date:%m-%d-%Y} at {vitals_display_date:%H:%M}.\"\n",
    "                if (vital_attribution['feature_value'] > 109):\n",
    "                    mapping_status = 'MAPPED'\n",
    "                else:\n",
    "                    mapping_status = 'DATA_FOUND'\n",
    "            # vitals - bmi\n",
    "            elif vital_type == 'bmi':\n",
    "                if vital_attribution['feature_value']>34:\n",
    "                    human_readable_name = f\"Obese BMI of {vital_attribution['feature_value']} recorded on {vitals_display_date:%m-%d-%Y}.\"\n",
    "                    mapping_status = 'MAPPED'\n",
    "                elif vital_attribution['feature_value']>14 and vital_attribution['feature_value']<17.6:\n",
    "                    human_readable_name = f\"Low BMI of {vital_attribution['feature_value']} recorded on {vitals_display_date:%m-%d-%Y}.\"\n",
    "                    mapping_status = 'MAPPED'\n",
    "                else:\n",
    "                    mapping_status = 'DATA_FOUND'\n",
    "            # vitals - diastolicvalue\n",
    "            elif aggregation=='Minimum' and vital_type=='diastolicvalue':\n",
    "                if vital_attribution['feature_value']>25 and vital_attribution['feature_value']<70:\n",
    "                    human_readable_name = f\"Low diastolic of {vital_attribution['feature_value']} recorded on {vitals_display_date:%m-%d-%Y} at {vitals_display_date:%H:%M}.\"\n",
    "                    mapping_status = 'MAPPED'\n",
    "                elif vital_attribution['feature_value']>92 and vital_attribution['feature_value']<200:\n",
    "                    human_readable_name = f\"High diastolic of {vital_attribution['feature_value']} recorded on {vitals_display_date:%m-%d-%Y} at {vitals_display_date:%H:%M}.\"\n",
    "                    mapping_status = 'MAPPED'\n",
    "                else:\n",
    "                    mapping_status = 'DATA_FOUND'\n",
    "            # vitals - O2 sats\n",
    "            elif aggregation=='Minimum' and vital_type=='O2 sats':\n",
    "                human_readable_name = f\"Low O2 saturation of {vital_attribution['feature_value']} recorded on {vitals_display_date:%m-%d-%Y} at {vitals_display_date:%H:%M}.\"\n",
    "                if vital_attribution['feature_value']>70 and vital_attribution['feature_value']<90:\n",
    "                    mapping_status = 'MAPPED'\n",
    "                else:\n",
    "                    mapping_status = 'DATA_FOUND'\n",
    "            # vitals - Temperature\n",
    "            elif vital_type == 'Temperature':\n",
    "                if aggregation == 'Minimum' and vital_attribution['feature_value'] > 85 and vital_attribution['feature_value'] < 97.5:\n",
    "                    human_readable_name = f\"Low body temperature of {vital_attribution['feature_value']} recorded on {vitals_display_date:%m-%d-%Y} at {vitals_display_date:%H:%M}.\"\n",
    "                    mapping_status = 'MAPPED'\n",
    "                elif aggregation == 'Maximum' and vital_attribution['feature_value'] > 99.9 and vital_attribution['feature_value'] < 108.6:\n",
    "                    human_readable_name = f\"High body temperature of {vital_attribution['feature_value']} recorded on {vitals_display_date:%m-%d-%Y} at {vitals_display_date:%H:%M}.\"\n",
    "                    mapping_status = 'MAPPED'\n",
    "                else:\n",
    "                    mapping_status = 'DATA_FOUND'\n",
    "            # vitals - Blood Sugar\n",
    "            elif vital_type == 'Blood Sugar':\n",
    "\n",
    "                if aggregation == 'Minimum' and vital_attribution['feature_value'] > 15 and vital_attribution['feature_value'] < 70:\n",
    "                    human_readable_name = f\"Low blood sugar of {vital_attribution['feature_value']} recorded on {vitals_display_date:%m-%d-%Y} at {vitals_display_date:%H:%M}.\"\n",
    "                    mapping_status = 'MAPPED'\n",
    "                elif aggregation == 'Maximum' and vital_attribution['feature_value'] > 245 and vital_attribution['feature_value'] < 525:\n",
    "                    human_readable_name = f\"High blood sugar of {vital_attribution['feature_value']} recorded on {vitals_display_date:%m-%d-%Y} at {vitals_display_date:%H:%M}.\"\n",
    "                    mapping_status = 'MAPPED'\n",
    "                else:\n",
    "                    mapping_status = 'DATA_FOUND'\n",
    "            # vitals - Respiration\n",
    "            elif aggregation == 'Maximum' and vital_type == 'Respiration':\n",
    "                human_readable_name = f\"High respiration of {vital_attribution['feature_value']} recorded on {vitals_display_date:%m-%d-%Y} at {vitals_display_date:%H:%M}.\"\n",
    "                if vital_attribution['feature_value'] > 27 and vital_attribution['feature_value'] < 70:\n",
    "                    mapping_status = 'MAPPED'\n",
    "                else:\n",
    "                    mapping_status = 'DATA_FOUND'\n",
    "            # vitals - BP-Systolic\n",
    "            elif aggregation=='Minimum' and vital_type=='BP-Systolic':\n",
    "                if vital_attribution['feature_value']>85 and vital_attribution['feature_value']<115:\n",
    "                    human_readable_name = f\"Low systolic of {vital_attribution['feature_value']} recorded on {vitals_display_date:%m-%d-%Y} at {vitals_display_date:%H:%M}.\"\n",
    "                    mapping_status = 'MAPPED'\n",
    "                elif vital_attribution['feature_value']>160 and vital_attribution['feature_value']<200:\n",
    "                    human_readable_name = f\"High systolic of {vital_attribution['feature_value']} recorded on {vitals_display_date:%m-%d-%Y} at {vitals_display_date:%H:%M}.\"\n",
    "                    mapping_status = 'MAPPED'\n",
    "                else:\n",
    "                    mapping_status = 'DATA_FOUND'\n",
    "\n",
    "        else:\n",
    "            mapping_status = 'DATA_NOT_FOUND'\n",
    "\n",
    "    elif diff_match:\n",
    "        aggfunc = diff_match.groups()[0]\n",
    "        vital_type = diff_match.groups()[1]\n",
    "        day_count = get_day_count(vital_attribution)\n",
    "        if day_count == 1:\n",
    "            day_word = \"day\"\n",
    "        else:\n",
    "            day_word = \"days\"\n",
    "        # print(f\"matched diff {aggfunc} and {vital_type}\")\n",
    "        if vital_attribution['feature_value'] < 0:\n",
    "            direction = 'decreased'\n",
    "        else:\n",
    "            direction = 'increased'\n",
    "        feature_value_str = format_float_str(abs(vital_attribution['feature_value']))\n",
    "        human_readable_name = f'Daily {aggfunc_mapping[aggfunc]} {vital_type} {direction} by {feature_value_str} over the last {day_count} {day_word}.'\n",
    "        mapping_status = 'DATA_FOUND'\n",
    "    elif rol_avg_match:\n",
    "        aggfunc = rol_avg_match.groups()[0]\n",
    "        vital_type = rol_avg_match.groups()[1]\n",
    "        day_count = get_day_count(vital_attribution)\n",
    "        # print(f\"matched rol_avg {aggfunc} and {vital_type}\")\n",
    "        feature_value_str = format_float_str(abs(vital_attribution['feature_value']))\n",
    "        human_readable_name = f'Average of daily {aggfunc_mapping[aggfunc]} {vital_type} over the last {day_count} days: {feature_value_str}.'\n",
    "        mapping_status = 'DATA_FOUND'\n",
    "    elif rol_std_match:\n",
    "        aggfunc = rol_std_match.groups()[0]\n",
    "        vital_type = rol_std_match.groups()[1]\n",
    "        day_count = get_day_count(vital_attribution)\n",
    "        # print(f\"matched std_avg {aggfunc} and {vital_type}\")\n",
    "        feature_value_str = format_float_str(abs(vital_attribution['feature_value']))\n",
    "        human_readable_name = f'Variation of daily {aggfunc_mapping[aggfunc]} {vital_type} over the last {day_count} days: {feature_value_str}.'\n",
    "        mapping_status = 'DATA_FOUND'\n",
    "\n",
    "    return pd.Series([human_readable_name, mapping_status], index=['a', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rehosp_mapper(rehosp_attribution, processed_df_dict, mpid_to_use, date_to_use):\n",
    "    rehosp_data = processed_df_dict['patient_rehosps']\n",
    "    human_readable_name = ''\n",
    "    mapping_status = 'NOT_MAPPED'\n",
    "    feature_value = rehosp_attribution[\"feature_value\"]\n",
    "    if rehosp_attribution['mapped_feature'].startswith('hosp_days_'):\n",
    "        rehosp_matches = rehosp_data[(rehosp_data.masterpatientid == mpid_to_use)]\n",
    "        # now get the most recent order (since it is already sorted by order_date)\n",
    "        rehosp_reason = rehosp_matches.tail(1).copy().reset_index(drop=True)\n",
    "        if (len(rehosp_reason) > 0):\n",
    "            human_readable_name = f'{int(feature_value)} days since last transfer.'\n",
    "            if feature_value <= 8:\n",
    "                mapping_status = 'MAPPED'\n",
    "            else:\n",
    "                mapping_status = 'DATA_FOUND'\n",
    "        else:\n",
    "            mapping_status = 'DATA_NOT_FOUND'\n",
    "    elif rehosp_attribution['mapped_feature'].startswith('hosp_count_'):\n",
    "        rehosp_matches = rehosp_data[(rehosp_data.masterpatientid == mpid_to_use)]\n",
    "        # now get the most recent order (since it is already sorted by date_of_transfer)\n",
    "        rehosp_reason = rehosp_matches.tail(1).copy().reset_index(drop=True)\n",
    "\n",
    "        if (len(rehosp_reason) > 0):\n",
    "            human_readable_name = f'{int(feature_value)} prior hospitalizations.'\n",
    "            mapping_status = 'MAPPED'\n",
    "        else:\n",
    "            mapping_status = 'DATA_NOT_FOUND'\n",
    "    return pd.Series([human_readable_name, mapping_status], index=['a', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_dict = process_raw_data(raw_data_dict)\n",
    "    \n",
    "    explainer = shap.TreeExplainer(model.model)\n",
    "    shap_values = explainer.shap_values(final_x)\n",
    "\n",
    "    shap_results = []\n",
    "\n",
    "    for idx, row in final_x.iterrows():\n",
    "        shaps = pd.DataFrame(\n",
    "            {\n",
    "                \"feature\": final_x.columns,\n",
    "                \"attribution_score\": shap_values[1][idx],\n",
    "                \"feature_value\": final_x.iloc[idx],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        shaps[\"masterpatientid\"] = final_idens.iloc[idx].masterpatientid\n",
    "        shaps[\"facilityid\"] = final_idens.iloc[idx].facilityid\n",
    "        shaps[\"censusdate\"] = final_idens.iloc[idx].censusdate\n",
    "\n",
    "        shap_results.append(shaps)\n",
    "\n",
    "\n",
    "    results = pd.concat(shap_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_attributions = results.groupby(['masterpatientid','facilityid']).apply(process_attributions).reset_index(drop=True)\n",
    "\n",
    "processed_attributions['censusdate'] = pd.to_datetime(processed_attributions.censusdate)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "processed_attributions.loc[processed_attributions.feature_type == 'Medication', ['human_readable_name','mapping_status']] = (\n",
    "    processed_attributions\n",
    "    .loc[processed_attributions.feature_type == 'Medication']\n",
    "    .apply(lambda x: med_mapper(x, ret_dict, x.masterpatientid, x.censusdate), axis=1)\n",
    "    .values\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_attributions.loc[processed_attributions.feature_type == 'Lab', ['human_readable_name','mapping_status']] = (\n",
    "    processed_attributions\n",
    "    .loc[processed_attributions.feature_type == 'Lab']\n",
    "    .apply(lambda x: lab_mapper(x, ret_dict, x.masterpatientid, x.censusdate), axis=1)\n",
    "    .values\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_attributions.loc[processed_attributions.feature_type == 'Medication'].to_csv('meds_notebook.csv',sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_attributions.loc[processed_attributions.feature_type == 'Diagnostic Order', ['human_readable_name', 'mapping_status']] = (\n",
    "    processed_attributions.\n",
    "    loc[processed_attributions.feature_type == 'Diagnostic Order']\n",
    "    .apply(lambda x: diagnostic_order_mapper(x, ret_dict, x.masterpatientid, x.censusdate), axis=1)\n",
    "    .values\n",
    "    )\n",
    "# processed_attributions[processed_attributions['feature_type'] == 'Diagnostic Order'].to_csv('diagnostic_notebook.csv', sep=',',\n",
    "#                                                                                       index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_attributions.loc[processed_attributions.feature_type == 'Diet Order', ['human_readable_name', 'mapping_status']] = (\n",
    "        processed_attributions.\n",
    "        loc[processed_attributions.feature_type == 'Diet Order']\n",
    "        .apply(lambda x: diet_order_mapper(x, ret_dict, x.masterpatientid, x.censusdate), axis=1)\n",
    "        .values\n",
    "    )\n",
    "# processed_attributions[processed_attributions['feature_type'] == 'Diet Order'].to_csv('diet_notebook.csv',\n",
    "#                                                                                       sep=',',\n",
    "#                                                                                       index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_attributions.loc[processed_attributions.feature_type == 'Alert', ['human_readable_name', 'mapping_status']] = (\n",
    "    processed_attributions.\n",
    "    loc[processed_attributions.feature_type == 'Alert']\n",
    "    .apply(lambda x: alert_mapper(x, ret_dict, x.masterpatientid, x.censusdate), axis=1)\n",
    "    .values\n",
    "    )\n",
    "# processed_attributions[processed_attributions['feature_type'] == 'Alert'].to_csv('alert_notebook.csv',\n",
    "#                                                                                  sep=',',\n",
    "#                                                                                  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_attributions.loc[processed_attributions.feature_type == 'Diagnosis', ['human_readable_name', 'mapping_status']] = (\n",
    "    processed_attributions\n",
    "    .loc[processed_attributions.feature_type == 'Diagnosis']\n",
    "    .apply(lambda x: dx_mapper(x, ret_dict, x.masterpatientid, x.censusdate), axis=1)\n",
    "    .values\n",
    "    )\n",
    "\n",
    "processed_attributions.loc[processed_attributions.feature_type == 'Diagnosis', :] = \\\n",
    "        processed_attributions.loc[(processed_attributions.feature_type == 'Diagnosis') & (~processed_attributions.duplicated(\n",
    "            subset=['masterpatientid', 'mapping_status', 'mapped_feature'],keep='first')),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_attributions.loc[processed_attributions.feature_type == 'Vital', ['human_readable_name', 'mapping_status']] = (\n",
    "    processed_attributions\n",
    "    .loc[processed_attributions.feature_type == 'Vital']\n",
    "    .apply(lambda x: vital_mapper(x, ret_dict, x.masterpatientid, x.censusdate), axis=1)\n",
    "    .values\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_attributions.to_csv('vitals_notebook.csv',sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_attributions.loc[\n",
    "        processed_attributions.feature_type == 'patient_rehosps', ['human_readable_name', 'mapping_status']] = (\n",
    "        processed_attributions.\n",
    "            loc[processed_attributions.feature_type == 'patient_rehosps']\n",
    "            .apply(lambda x: rehosp_mapper(x, ret_dict, x.masterpatientid, x.censusdate), axis=1)\n",
    "            .values\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_attributions[\"client\"] = client\n",
    "processed_attributions[\"modelid\"] = model.model_name\n",
    "processed_attributions[\"attribution_rank\"] = processed_attributions.groupby([\"masterpatientid\"]).attribution_percent.rank(\n",
    "    ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = processed_attributions.reindex(\n",
    "        columns=[\n",
    "            \"censusdate\",\n",
    "            \"masterpatientid\",\n",
    "            \"facilityid\",\n",
    "            \"client\",\n",
    "            \"modelid\",\n",
    "            \"feature\",\n",
    "            \"feature_value\",\n",
    "            \"feature_type\",\n",
    "            \"human_readable_name\",\n",
    "            \"attribution_score\",\n",
    "            \"attribution_rank\",\n",
    "            \"sum_attribution_score\",\n",
    "            \"attribution_percent\",\n",
    "            \"mapping_status\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "final = (final.loc[final.attribution_rank <= 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Lab Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_attributions[(processed_attributions.feature_type == \"Lab\") & (processed_attributions.mapping_status == 'MAPPED')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_attributions[(processed_attributions.feature_type == \"Lab\") & (processed_attributions.mapping_status == 'NOT_MAPPED')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_attributions[(processed_attributions.feature_type == \"Lab\")]['mapping_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(processed_attributions[(processed_attributions.feature_type == \"Lab\") & (processed_attributions.mapping_status == 'MAPPED')]['human_readable_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_attributions[(processed_attributions.feature_type == \"Lab\") & (processed_attributions.mapping_status == 'NOT_MAPPED') & (processed_attributions.feature_value != 0) &\n",
    "                       ~(processed_attributions.mapped_feature.str.startswith('na_indictator'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_attributions[(processed_attributions.feature_type == \"Lab\") & (processed_attributions.mapping_status == 'NOT_MAPPED') &\n",
    "                       ~(processed_attributions.mapped_feature.str.startswith('na_indictator'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_attributions[(processed_attributions.feature_type == \"Lab\") & (processed_attributions.mapping_status == 'MAPPED')].iloc[1]['human_readable_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_attributions[(processed_attributions.feature_type == \"Lab\") & (processed_attributions.feature_value != 0) & ~(processed_attributions.feature.str.contains('na_indictator'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs = ret_dict['patient_lab_results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs[(labs.masterpatientid == 907) & (labs.profiledescription == 'BICARBONATE')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_attributions['feature_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Meds Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_attributions[(processed_attributions.feature_type == \"Medication\")]['mapping_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_attributions[(processed_attributions.feature_type == \"Medication\") & (processed_attributions.mapping_status == 'MAPPED')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(processed_attributions[(processed_attributions.feature_type == \"Medication\") & (processed_attributions.mapping_status == 'MAPPED')]['human_readable_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_attributions[(processed_attributions.feature_type == \"Medication\") & (processed_attributions.mapping_status == 'DATA_NOT_FOUND')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meds = ret_dict['patient_meds']\n",
    "meds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
