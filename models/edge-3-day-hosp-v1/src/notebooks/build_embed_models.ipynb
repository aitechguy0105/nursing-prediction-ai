{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progress Notes\n",
    "## Build Word Vector Models\n",
    "Run tokenizer and phrase detection, save corpus and train fasttext embeddings.  Save tokenized notes dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import scipy\n",
    "import gc\n",
    "import re\n",
    "\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import FastText\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/src')\n",
    "from shared import data\n",
    "from shared import notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = data.load_raw_data_from_files('/data/raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "note_parts = data_dict['progress_notes']\n",
    "note_parts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "note_parts = note_parts.sort_values(['MasterPatientID', \n",
    "                                    'ProgressNoteID', \n",
    "                                   'SectionSequence', \n",
    "                                   'NoteTextOrder'])\n",
    "note_parts = note_parts.reset_index(drop=True)\n",
    "grp_cols = ['MasterPatientID', 'FacilityID', 'ProgressNoteID', \n",
    "            'ProgressNoteType', 'Section', 'SectionSequence', \n",
    "            'CreatedDate']\n",
    "stitched_notes = note_parts.groupby(grp_cols).agg({'NoteText': lambda x: ''.join(x)}).reset_index()\n",
    "stitched_notes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Filter eMAR & Progress Notes\n",
    "\n",
    "print(\"Splitting notes into eMAR and other notes...\")\n",
    "note_types = np.array([str(el) for el in stitched_notes.ProgressNoteType.unique()])\n",
    "emar_sel = np.array([re.match(r'emar', note_type, re.IGNORECASE) is not None for note_type in note_types])\n",
    "emar_note_types = note_types[emar_sel]\n",
    "is_emar = stitched_notes['ProgressNoteType'].isin(emar_note_types)\n",
    "emar_notes = stitched_notes.loc[is_emar]\n",
    "progress_notes = stitched_notes.loc[~is_emar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get rid of notes with no note text\n",
    "\n",
    "mask = emar_notes.NoteText == ''\n",
    "mask = mask.values\n",
    "emar_notes = emar_notes[~mask]\n",
    "\n",
    "mask = progress_notes.NoteText == ''\n",
    "mask = mask.values\n",
    "progress_notes = progress_notes[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save again - duh. \n",
    "\n",
    "print(\"Saving stitched eMAR and progress notes...\")\n",
    "emar_notes.to_parquet('/data/raw/emar_notes.parquet')\n",
    "progress_notes.to_parquet('/data/raw/pn_notes.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Filter out notes after val start date (train end date)\n",
    "\n",
    "train_end_date = pd.Timestamp('2019-07-31')\n",
    "sel = (emar_notes.CreatedDate <= train_end_date).values\n",
    "print(emar_notes.shape)\n",
    "emar_notes = emar_notes[sel]\n",
    "print(emar_notes.shape)\n",
    "\n",
    "sel = (progress_notes.CreatedDate <= train_end_date).values\n",
    "print(progress_notes.shape)\n",
    "progress_notes = progress_notes[sel]\n",
    "print(progress_notes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get corpora, generate phrases, save corpora with phrases... \n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def _processNote(note_text): \n",
    "    word_list = simple_preprocess(note_text, max_len=25)\n",
    "    words = \" \".join(word_list)\n",
    "    return words\n",
    "\n",
    "print(f'Processing {len(progress_notes)} progress notes')\n",
    "with Pool(os.cpu_count() - 4) as pool: \n",
    "    pn_sentences = pool.map(_processNote, progress_notes.NoteText.values)\n",
    "\n",
    "print(f'Processing {len(emar_notes)} eMAR notes')    \n",
    "with Pool(os.cpu_count() - 4) as pool: \n",
    "    emar_sentences = pool.map(_processNote, emar_notes.NoteText.values)\n",
    "    \n",
    "print('Done...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Write corpora to file\n",
    "\n",
    "print(\"Writing progress note corpus...\")\n",
    "pn_corpus_file = \"/data/raw/pn_corpus.txt\"\n",
    "with open(pn_corpus_file, \"w\") as f_out: \n",
    "    f_out.write(\"\\n\".join(pn_sentences))\n",
    "\n",
    "print(\"Writing emar note corpus...\")\n",
    "emar_corpus_file = \"/data/raw/emar_corpus.txt\"        \n",
    "with open(emar_corpus_file, \"w\") as f_out: \n",
    "    f_out.write(\"\\n\".join(emar_sentences))\n",
    "\n",
    "print('Done...')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "num_threads = os.cpu_count() - 8\n",
    "\n",
    "# Fit fasttext embeddings to these...\n",
    "embed_dim = 200\n",
    "num_iter = 3\n",
    "print(f\"Fitting fasttext for pn phrases\")\n",
    "pn_model = FastText(corpus_file='/data/raw/pn_corpus.txt', \n",
    "                    size=embed_dim, \n",
    "                    sg=1, \n",
    "                    iter=num_iter,\n",
    "                    negative=10,\n",
    "                    workers=num_threads)\n",
    "pn_model.save(f\"/data/models/ft_progress_notes_d{embed_dim}.model\")\n",
    "\n",
    "print(f\"Fitting fasttext for emar phrases\")\n",
    "emar_model = FastText(corpus_file='/data/raw/emar_corpus.txt',  \n",
    "                      size=embed_dim, \n",
    "                      sg=1, \n",
    "                      iter=num_iter,\n",
    "                      negative=10,\n",
    "                      workers=num_threads)\n",
    "emar_model.save(f\"/data/models/ft_emar_notes_d{embed_dim}.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
