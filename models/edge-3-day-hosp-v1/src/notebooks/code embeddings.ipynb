{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code embeddings\n",
    "Get fasttext embeddings for dx and rx codes.  Treat each stay as a sentence, and the corpus is composed of multiple random permutations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import scipy\n",
    "import gc\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from gensim.models import FastText\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/code')\n",
    "from edge import data\n",
    "from edge import patient_stays\n",
    "from edge import diagnosis\n",
    "from edge import meds\n",
    "from edge import vitals\n",
    "from edge import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14694483, 4), (118127, 19))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_ptimes = pd.read_parquet('/data/raw/combined_ptimes.parquet')\n",
    "combined_stays = pd.read_parquet('/data/raw/combined_stays.parquet')\n",
    "combined_ptimes.shape, combined_stays.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<14694483x5070 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 294388924 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dx = scipy.sparse.load_npz('/data/processed/combined_dx_features_csr.npz')\n",
    "combined_rx = scipy.sparse.load_npz('/data/processed/combined_rx_features_csr.npz')\n",
    "\n",
    "combined_codes = scipy.sparse.hstack([combined_dx, combined_rx])\n",
    "combined_codes = scipy.sparse.csr_matrix(combined_codes)\n",
    "combined_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/processed/combined_dx_colnames.pkl', 'rb') as f_in: \n",
    "    dx_colnames = pkl.load(f_in)\n",
    "with open('/data/processed/combined_rx_colnames.pkl', 'rb') as f_in: \n",
    "    rx_colnames = pkl.load(f_in)    \n",
    "rx_colnames = np.array([c.replace(' ', '_') for c in rx_colnames])\n",
    "code_vocab = np.concatenate([dx_colnames, rx_colnames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map codes in vocab to indices\n",
    "code_to_index = {k:(v+1) for v, k in enumerate(code_vocab)}\n",
    "with open('/data/raw/code_to_index_map.pkl', 'wb') as f_out: \n",
    "    pkl.dump(code_to_index, file=f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_ptimes = combined_ptimes.groupby(['MasterPatientID', 'StayRowIndex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing jobs data\n",
      "Got 116667 jobs...\n"
     ]
    }
   ],
   "source": [
    "print('Constructing jobs data')\n",
    "groups_list = []\n",
    "for group_idx, group in grouped_ptimes: \n",
    "    groups_list.append(group)\n",
    "print(f'Got {len(groups_list)} jobs...')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_permutations = 4\n",
    "\n",
    "def stayWorker(group): \n",
    "    indices = group.index.values\n",
    "    this_dx = np.asarray(combined_dx[indices].todense())\n",
    "    this_rx = np.asarray(combined_rx[indices].todense())\n",
    "    dx_col_sums = np.sum(this_dx, axis=0)\n",
    "    rx_col_sums = np.sum(this_rx, axis=0)\n",
    "    dx_sel = np.nonzero(dx_col_sums > 0)[0]\n",
    "    rx_sel = np.nonzero(rx_col_sums > 0)[0]\n",
    "#    dx_indices = [code_to_index[c] for c in dx_colnames[dx_sel]]\n",
    "#    rx_indices = [code_to_index[c] for c in rx_colnames[rx_sel]]\n",
    "#    codes_for_stay = np.concatenate([dx_indices, rx_indices])\n",
    "    dx_codes = dx_colnames[dx_sel]\n",
    "    rx_codes = rx_colnames[rx_sel]\n",
    "    codes_for_stay = np.concatenate([dx_codes, rx_codes])\n",
    "    sentences = []\n",
    "    for i in range(num_permutations): \n",
    "        codes_for_stay = np.random.permutation(codes_for_stay)\n",
    "        code_sentence = \" \".join(codes_for_stay)\n",
    "        sentences.append(code_sentence)\n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staring jobs...\n"
     ]
    }
   ],
   "source": [
    "print('Staring jobs...')\n",
    "code_sentences = []\n",
    "with Pool(os.cpu_count() - 4) as pool: \n",
    "    code_sentence_lists = pool.map(stayWorker, groups_list)\n",
    "\n",
    "print('Collating code sentences...')\n",
    "for code_sentence_list in code_sentence_lists:     \n",
    "    code_sentences.extend(code_sentence_list)\n",
    "\n",
    "print('Done...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "466668"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(code_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done...\n"
     ]
    }
   ],
   "source": [
    "# Save \"corpus\"\n",
    "with open('/data/raw/code_sentence_corpus.txt', 'w') as f_out: \n",
    "    for code_sentence in code_sentences: \n",
    "        print(code_sentence, file=f_out)\n",
    "print('Done...')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting fasttext for pn phrases\n",
      "Done...\n"
     ]
    }
   ],
   "source": [
    "# Fit model. \n",
    "num_threads = os.cpu_count() - 4\n",
    "\n",
    "# Fit fasttext embeddings to these...\n",
    "embed_dim = 200\n",
    "num_iter = 3\n",
    "print(f\"Fitting fasttext for codes\")\n",
    "code_model = FastText(corpus_file='/data/raw/code_sentence_corpus.txt', \n",
    "                      size=embed_dim, \n",
    "                      sg=1, \n",
    "                      iter=num_iter,\n",
    "                      negative=10,\n",
    "                      workers=num_threads)\n",
    "code_model.save(f\"/data/model/ft_combined_codes_d{embed_dim}.model\")\n",
    "print('Done...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
