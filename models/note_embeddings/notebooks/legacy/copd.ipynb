{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.engine.url import URL\n",
    "\n",
    "from sklearn.ensemble import forest, gradient_boosting\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest\n",
    "\n",
    "import mlflow\n",
    "from mlflow import log_metric, log_param, log_artifact\n",
    "from mlflow.sklearn import log_model\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "#import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start_date = '2017-01-01'\n",
    "train_end_date = '2019-02-28'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secret_name = \"cust_db_credentials\"\n",
    "region_name = \"us-east-1\"\n",
    "\n",
    "# Create a Secrets Manager client\n",
    "session = boto3.session.Session()\n",
    "client = session.client(service_name=\"secretsmanager\", region_name=region_name)\n",
    "\n",
    "get_secret_value_response = client.get_secret_value(SecretId=secret_name)\n",
    "\n",
    "db_info = json.loads(get_secret_value_response[\"SecretString\"])\n",
    "\n",
    "avan_connect_url = URL(\n",
    "    drivername=\"mssql+pyodbc\",\n",
    "    username=db_info[\"username\"],\n",
    "    password=db_info[\"password\"],\n",
    "    host=db_info[\"host\"],\n",
    "    database=\"AVAN\",\n",
    "    query={'driver': 'ODBC Driver 17 for SQL Server'}\n",
    ")\n",
    "\n",
    "avan_engine = create_engine(avan_connect_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avante Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avan_engine.execute('select 1').fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('/code/data/raw')\n",
    "data_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f'''\n",
    "select patientid, facilityid, masterpatientid\n",
    "from view_ods_facility_patient\n",
    "where facilityid in (select facilityid from view_ods_facility where lineofbusiness = 'SNF')\n",
    "'''\n",
    "\n",
    "master_patient_lookup = pd.read_sql(query, con=avan_engine)\n",
    "master_patient_lookup.to_parquet(data_path/'master_patient_lookup.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f'''\n",
    "select patientid, facilityid, dateoftransfer, purposeofstay, transferredto,\n",
    "orderedbyid, transferreason, otherreasonfortransfer, planned,\n",
    "hospitaldischargedate, primaryphysicianid \n",
    "from view_ods_hospital_transfers_transfer_log_v2\n",
    "where dateoftransfer between '{train_start_date}' and '{train_end_date}'\n",
    "and facilityid in (select facilityid from view_ods_facility where lineofbusiness = 'SNF')\n",
    "'''\n",
    "\n",
    "patient_rehosps = pd.read_sql(query, con=avan_engine)\n",
    "patient_rehosps = patient_rehosps.merge(master_patient_lookup, on=['patientid', 'facilityid'])\n",
    "patient_rehosps.to_parquet(data_path/'patient_rehosps.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f'''\n",
    "select masterpatientid, gender, dateofbirth, education, citizenship, race, religion, state, primarylanguage\n",
    "from view_ods_master_patient\n",
    "'''\n",
    "\n",
    "patient_demographics = pd.read_sql(query, con=avan_engine)\n",
    "patient_demographics.to_parquet(data_path/'patient_demographics.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f'''\n",
    "select clientid as patientid, censusdate, facilityid, bedid, beddescription, roomratetypedescription, payercode, carelevelcode\n",
    "from view_ods_daily_census_v2\n",
    "where censusdate between '{train_start_date}' and '{train_end_date}'\n",
    "and facilityid in (select facilityid from view_ods_facility where lineofbusiness = 'SNF')\n",
    "'''\n",
    "\n",
    "patient_census = pd.read_sql(query, con=avan_engine)\n",
    "patient_census = patient_census.merge(master_patient_lookup, on=['patientid','facilityid'])\n",
    "patient_census.to_parquet(data_path/'patient_census.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f'''\n",
    "select patientid, onsetdate, facilityid, diagnosiscode, diagnosisdesc, classification, rank\n",
    "from view_ods_patient_diagnosis\n",
    "where onsetdate between '{train_start_date}' and '{train_end_date}'\n",
    "and facilityid in (select facilityid from view_ods_facility where lineofbusiness = 'SNF')\n",
    "'''\n",
    "\n",
    "patient_diagnosis = pd.read_sql(query, con=avan_engine)\n",
    "patient_diagnosis = patient_diagnosis.merge(master_patient_lookup, on=['patientid','facilityid'])\n",
    "patient_diagnosis.to_parquet(data_path/'patient_diagnosis.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f'''\n",
    "select clientid as patientid, facilityid, date, bmi, vitalsdescription, value, diastolicvalue, warnings\n",
    "from view_ods_Patient_weights_vitals\n",
    "where date between '{train_start_date}' and '{train_end_date}'\n",
    "and facilityid in (select facilityid from view_ods_facility where lineofbusiness = 'SNF')\n",
    "and clientid in (select distinct clientid from view_ods_daily_census_v2 where censusdate between '{train_start_date}' and '{train_end_date}')\n",
    "'''\n",
    "\n",
    "patient_vitals = pd.read_sql(query, con=avan_engine)\n",
    "patient_vitals = patient_vitals.merge(master_patient_lookup, on=['patientid', 'facilityid'])\n",
    "patient_vitals.to_parquet(data_path/'patient_vitals.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f'''\n",
    "select distinct patientid, facilityid, orderdate, gpiclassdescription, gpisubclassdescription\n",
    "from view_ods_physician_order_list_v2 a\n",
    "inner join view_ods_physician_order_list_med b\n",
    "on a.PhysicianOrderID = b.PhysiciansOrderID \n",
    "where orderdate between '{train_start_date}' and '{train_end_date}';\n",
    "'''\n",
    "\n",
    "patient_meds = pd.read_sql(query, con=avan_engine)\n",
    "patient_meds = patient_meds.merge(master_patient_lookup, on=['patientid', 'facilityid'])\n",
    "patient_meds.to_parquet(data_path/'patient_meds.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f'''\n",
    "select distinct patientid, facilityid, orderdate, ordercategory, ordertype, orderdescription, pharmacymedicationname, diettype, diettexture, dietsupplement\n",
    "from view_ods_physician_order_list_v2\n",
    "where orderdate between '{train_start_date}' and '{train_end_date}'\n",
    "and ordercategory in ('Diagnostic', 'Enteral - Feeding', 'Dietary - Diet', 'Dietary - Supplements')\n",
    "'''\n",
    "\n",
    "patient_orders = pd.read_sql(query, con=avan_engine)\n",
    "patient_orders = patient_orders.merge(master_patient_lookup, on=['patientid','facilityid'])\n",
    "patient_orders.to_parquet(data_path/'patient_orders.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f'''\n",
    "select distinct patientid, facilityid, orderdate, ordercategory, ordertype, orderdescription, pharmacymedicationname, diettype, diettexture, dietsupplement\n",
    "from view_ods_physician_order_list_v2\n",
    "where orderdate between '{train_start_date}' and '{train_end_date}'\n",
    "and ordercategory in ('Pharmacy', 'Diagnostic', 'Enteral - Feeding', 'Dietary - Diet', 'Dietary - Supplements')\n",
    "'''\n",
    "\n",
    "patient_orders = pd.read_sql(query, con=avan_engine)\n",
    "patient_orders = patient_orders.merge(master_patient_lookup, on=['patientid','facilityid'])\n",
    "patient_orders.to_parquet(data_path/'patient_orders.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detailed results seem to only start on 2019-03-03 and onwards - commenting out for now, revisit when we have more data\n",
    "\n",
    "#query = f'''\n",
    "#select c.patientid, a.resultdate, a.profiledescription, a.referencerange, a.result, a.abnormalityid, e.abnormalitydescription, b.reportdesciption, b.severityid, d.severitydescription from view_ods_result_lab_report_detail a\n",
    "#left join view_ods_result_lab_report b on a.LabReportID = b.LabReportID\n",
    "#left join view_ods_result_order_source c on b.ResultOrderSourceID = c.ResultOrderSourceID\n",
    "#left join view_ods_result_lab_report_severity d on b.SeverityID = d.SeverityID\n",
    "#left join view_ods_result_lab_test_abnormality e on a.AbnormalityID = e.AbnormalityID\n",
    "#'''\n",
    "\n",
    "#patient_lab_results = pd.read_sql(query, con=avan_engine)\n",
    "#patient_lab_results.to_parquet(data_path/'patient_detailed_lab_results.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f'''\n",
    "select patientid, facilityid, createddate, stdalertid, alertdescription, a.triggereditemtype, description\n",
    "from [view_ods_cr_alert] a left join view_ods_cr_alert_triggered_item_type b\n",
    "on a.triggereditemtype = b.triggereditemtype\n",
    "where createddate between '{train_start_date}' and '{train_end_date}' and \n",
    "((triggereditemid is not null) or (a.triggereditemtype is not null))\n",
    "'''\n",
    "\n",
    "patient_alerts = pd.read_sql(query, con=avan_engine)\n",
    "patient_alerts = patient_alerts.merge(master_patient_lookup, on=['patientid','facilityid'])\n",
    "patient_alerts.to_parquet(data_path/'patient_alerts.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_demographics = pd.read_parquet(data_path/'patient_demographics.parquet')\n",
    "patient_orders = pd.read_parquet(data_path/'patient_orders.parquet')\n",
    "patient_vitals = pd.read_parquet(data_path/'patient_vitals.parquet')\n",
    "patient_rehosps = pd.read_parquet(data_path/'patient_rehosps.parquet')\n",
    "patient_orders = pd.read_parquet(data_path/'patient_orders.parquet')\n",
    "patient_census = pd.read_parquet(data_path/'patient_census.parquet')\n",
    "patient_diagnosis = pd.read_parquet(data_path/'patient_diagnosis.parquet')\n",
    "patient_alerts = pd.read_parquet(data_path/'patient_alerts.parquet')\n",
    "patient_meds = pd.read_parquet(data_path/'patient_meds.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorter(df, sort_keys=[]):\n",
    "    return df.sort_values(by=sort_keys)\n",
    "\n",
    "def deduper(df, unique_keys=[]):\n",
    "    df = df.drop_duplicates(subset=unique_keys, keep='last')\n",
    "    assert df.duplicated(subset=unique_keys).sum() == 0, f'''Still have dupes!'''\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_census = sorter(patient_census, sort_keys=['masterpatientid', 'censusdate'])\n",
    "patient_vitals = sorter(patient_vitals, sort_keys=['masterpatientid', 'date'])\n",
    "patient_orders = sorter(patient_orders, sort_keys=['masterpatientid', 'orderdate'])\n",
    "patient_rehosps = sorter(patient_rehosps, sort_keys=['masterpatientid', 'dateoftransfer'])\n",
    "patient_alerts = sorter(patient_alerts, sort_keys=['masterpatientid', 'createddate'])\n",
    "patient_meds = sorter(patient_meds, sort_keys=['masterpatientid', 'orderdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_census = deduper(patient_census, unique_keys=['masterpatientid', 'censusdate'])\n",
    "patient_demographics = deduper(patient_demographics, unique_keys=['masterpatientid'])\n",
    "patient_vitals = deduper(patient_vitals, unique_keys=['masterpatientid', 'date', 'vitalsdescription'])\n",
    "patient_orders = deduper(patient_orders, unique_keys=['masterpatientid', 'orderdate', 'orderdescription'])\n",
    "patient_rehosps = deduper(patient_rehosps, unique_keys=['masterpatientid', 'dateoftransfer'])\n",
    "patient_alerts = deduper(patient_alerts, unique_keys=['masterpatientid', 'createddate', 'alertdescription'])\n",
    "patient_meds = deduper(patient_meds, unique_keys=['masterpatientid', 'orderdate', 'gpisubclassdescription'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = pd.DataFrame({'censusdate': pd.date_range(start='2017-01-01', end='2019-02-28')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_rehosps['dateoftransfer'] = pd.to_datetime(patient_rehosps.dateoftransfer.dt.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base2 = base.merge(patient_census, how='left', on=['censusdate'])\n",
    "base3 = base2.merge(patient_demographics, how='left', on=['masterpatientid'])\n",
    "\n",
    "del base2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vitals = patient_vitals.set_index(keys=['masterpatientid','facilityid','date']).drop(columns='patientid')\n",
    "vitals['warnings'] = vitals.warnings.notna()\n",
    "\n",
    "diastolic = vitals.pop('diastolicvalue')\n",
    "diastolic = diastolic.dropna()\n",
    "\n",
    "warnings = vitals.pop('warnings')\n",
    "bmi = vitals.pop('bmi')\n",
    "\n",
    "vitals = vitals.reset_index()\n",
    "diastolic = diastolic.reset_index()\n",
    "warnings = warnings.reset_index()\n",
    "bmi = bmi.reset_index()\n",
    "\n",
    "bmi['bmi'] = bmi.bmi.replace({'Height required': None, 'Height and weight required':None, 'Weight required':None}).astype(float)\n",
    "\n",
    "vitals['date'] = vitals.pop('date').dt.date\n",
    "diastolic['date'] = diastolic.pop('date').dt.date\n",
    "warnings['date'] = warnings.pop('date').dt.date\n",
    "bmi['date'] = bmi.pop('date').dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggs=['median','std', 'max', 'min']\n",
    "vitals_pivoted = vitals.pivot_table(index=['masterpatientid','facilityid', 'date'], values='value', columns='vitalsdescription', aggfunc=aggs).reset_index()\n",
    "diastolic_pivoted = diastolic.pivot_table(index=['masterpatientid','facilityid', 'date'], values='diastolicvalue', aggfunc=aggs).reset_index()\n",
    "warnings_pivoted = warnings.pivot_table(index=['masterpatientid', 'facilityid', 'date'], values='warnings', aggfunc=sum).reset_index()\n",
    "bmi_pivoted = bmi.pivot_table(index=['masterpatientid', 'facilityid', 'date'], values='bmi', aggfunc=max).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_multi_columns(cols):\n",
    "    new_cols = []\n",
    "    \n",
    "    for col in cols:\n",
    "        if col[1] == '':\n",
    "            new_cols.append(col[0])\n",
    "        else:\n",
    "            new_cols.append('_'.join(col))\n",
    "            \n",
    "    return new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vitals_pivoted.columns = clean_multi_columns(vitals_pivoted.columns)\n",
    "diastolic_pivoted.columns = clean_multi_columns(diastolic_pivoted.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings_pivoted['date'] = pd.to_datetime(warnings_pivoted['date'])\n",
    "bmi_pivoted['date'] = pd.to_datetime(bmi_pivoted['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vitals_pivoted = vitals_pivoted.drop_duplicates(subset=['masterpatientid','date'], keep='last')\n",
    "diastolic_pivoted = diastolic_pivoted.drop_duplicates(subset=['masterpatientid','date'], keep='last')\n",
    "warnings_pivoted = warnings_pivoted.drop_duplicates(subset=['masterpatientid','date'], keep='last')\n",
    "bmi_pivoted = bmi_pivoted.drop_duplicates(subset=['masterpatientid','date'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vitals_base = vitals_pivoted.merge(diastolic_pivoted, how='left', on=['masterpatientid', 'facilityid', 'date'])\n",
    "vitals_base2 = vitals_base.merge(warnings_pivoted, how='left', on=['masterpatientid', 'facilityid', 'date'])\n",
    "vitals_final = vitals_base2.merge(bmi_pivoted, how='left', on=['masterpatientid', 'facilityid', 'date'])\n",
    "vitals_final.columns = 'vtl_' + vitals_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base4 = base3.merge(vitals_final, how='left', left_on=['masterpatientid','facilityid','censusdate'], right_on=['vtl_masterpatientid', 'vtl_facilityid','vtl_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del vitals; del vitals_pivoted; del diastolic_pivoted; del warnings_pivoted; del bmi_pivoted; del vitals_base; del vitals_base2; del vitals_final; del base3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_ccs = pd.read_csv('/code/data/lookup_tables/ccs_dx_icd10cm_2019_1.csv')\n",
    "lookup_ccs.columns = lookup_ccs.columns.str.replace(\"'\",\"\")\n",
    "lookup_ccs = lookup_ccs.apply(lambda x: x.str.replace(\"'\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_diagnosis['indicator'] = 1\n",
    "patient_diagnosis['diagnosiscode'] = patient_diagnosis.diagnosiscode.str.replace('.','')\n",
    "patient_diagnosis['onsetdate'] = patient_diagnosis.onsetdate.dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_diagnosis = patient_diagnosis.merge(lookup_ccs, how='left', left_on=['diagnosiscode'], right_on=['ICD-10-CM CODE'])\n",
    "patient_diagnosis['ccs_label'] = patient_diagnosis['MULTI CCS LVL 1 LABEL'] + ' - ' + patient_diagnosis['MULTI CCS LVL 2 LABEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_pivoted = patient_diagnosis.loc[:,['masterpatientid', 'onsetdate', 'ccs_label', 'indicator']].pivot_table(index=['masterpatientid', 'onsetdate'], columns=['ccs_label'], values='indicator', fill_value=0).reset_index()\n",
    "diagnosis_pivoted['onsetdate'] = pd.to_datetime(diagnosis_pivoted.onsetdate)\n",
    "diagnosis_pivoted.columns = 'dx_' + diagnosis_pivoted.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base5 = base4.merge(diagnosis_pivoted, how='left', left_on=['masterpatientid','censusdate'], right_on=['dx_masterpatientid','dx_onsetdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del base4; del diagnosis_pivoted;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_meds.loc[patient_meds.gpisubclassdescription.isna(), 'gpisubclassdescription'] = patient_meds.loc[patient_meds.gpisubclassdescription.isna(), 'gpiclassdescription']\n",
    "patient_meds['orderdate'] = patient_meds.orderdate.dt.date\n",
    "patient_meds['indicator'] = 1\n",
    "meds_pivoted = patient_meds.loc[:,['masterpatientid', 'orderdate', 'gpisubclassdescription', 'indicator']].pivot_table(index=['masterpatientid', 'orderdate'], columns=['gpisubclassdescription'], values='indicator', fill_value=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meds_pivoted.columns = 'med_' + meds_pivoted.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meds_pivoted = meds_pivoted.drop_duplicates(subset=['med_masterpatientid','med_orderdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meds_pivoted['med_orderdate'] = pd.to_datetime(meds_pivoted.med_orderdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base6 = base5.merge(meds_pivoted, how='left', left_on=['masterpatientid', 'censusdate'], right_on=['med_masterpatientid', 'med_orderdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del base5; del meds_pivoted;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostic_orders = patient_orders.loc[patient_orders.ordercategory == 'Diagnostic']\n",
    "diagnostic_orders['orderdate'] = diagnostic_orders.orderdate.dt.date\n",
    "diagnostic_orders['count_indicator_diagnostic_orders'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostic_pivoted = diagnostic_orders.drop(columns=['patientid', 'ordercategory', 'ordertype', 'orderdescription', 'pharmacymedicationname', 'diettype', 'diettexture', 'dietsupplement']).pivot_table(index=['masterpatientid', 'facilityid', 'orderdate'], values=['count_indicator_diagnostic_orders'], aggfunc=sum).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostic_pivoted['orderdate'] = pd.to_datetime(diagnostic_pivoted.orderdate)\n",
    "diagnostic_pivoted.columns = 'order_' + diagnostic_pivoted.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base7 = base6.merge(diagnostic_pivoted, how='left', left_on=['masterpatientid','facilityid','censusdate'], right_on=['order_masterpatientid','order_facilityid','order_orderdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del base6; del diagnostic_pivoted; del diagnostic_orders;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diet_orders = patient_orders[patient_orders.ordercategory == 'Dietary - Diet']\n",
    "diet_orders['orderdate'] = diet_orders.orderdate.dt.date\n",
    "diet_orders['indicator'] = 1\n",
    "diet_orders = diet_orders.drop_duplicates(subset=['masterpatientid', 'orderdate', 'diettype', 'diettexture'])\n",
    "\n",
    "diet_type_pivoted = diet_orders.loc[:,['masterpatientid', 'orderdate', 'diettype', 'indicator']].pivot_table(index=['masterpatientid', 'orderdate'], columns=['diettype'], values='indicator', aggfunc=min).reset_index()\n",
    "#diet_type_pivoted.columns = clean_multi_columns(diet_type_pivoted)\n",
    "diet_type_pivoted.head()\n",
    "diet_type_pivoted['orderdate'] = pd.to_datetime(diet_type_pivoted.orderdate)\n",
    "diet_type_pivoted.columns = 'order_' + diet_type_pivoted.columns\n",
    "\n",
    "diet_texture_pivoted = diet_orders.loc[:,['masterpatientid', 'orderdate', 'diettexture', 'indicator']].pivot_table(index=['masterpatientid', 'orderdate'], columns=['diettexture'], values='indicator', aggfunc=min).reset_index()\n",
    "#diet_texture_pivoted.columns = clean_multi_columns(diet_texture_pivoted)\n",
    "diet_texture_pivoted['orderdate'] = pd.to_datetime(diet_texture_pivoted.orderdate)\n",
    "diet_texture_pivoted.columns = 'order_' + diet_texture_pivoted.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base8 = base7.merge(diet_type_pivoted, how='left', left_on=['masterpatientid','censusdate'], right_on=['order_masterpatientid','order_orderdate'])\n",
    "base8 = base7.merge(diet_texture_pivoted, how='left', left_on=['masterpatientid','censusdate'], right_on=['order_masterpatientid','order_orderdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del base7;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diet_supplements = patient_orders[patient_orders.ordercategory == 'Dietary - Supplements']\n",
    "diet_supplements['orderdate'] = diet_supplements.orderdate.dt.date\n",
    "diet_supplements['indicator'] = 1\n",
    "diet_supplements = diet_supplements.drop_duplicates(subset=['masterpatientid', 'orderdate', 'dietsupplement'])\n",
    "                                                    \n",
    "diet_supplements_pivoted = diet_supplements.loc[:,['masterpatientid', 'orderdate', 'dietsupplement', 'indicator']].pivot_table(index=['masterpatientid', 'orderdate'], columns='dietsupplement', values='indicator', aggfunc=min).reset_index()\n",
    "diet_supplements_pivoted['orderdate'] = pd.to_datetime(diet_supplements_pivoted.orderdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diet_supplements_counts = diet_supplements.groupby(['masterpatientid', 'facilityid', 'orderdate']).dietsupplement.count().reset_index().rename(columns={'dietsupplement':'count_indicator_dietsupplement'})\n",
    "diet_supplements_counts['orderdate'] = pd.to_datetime(diet_supplements_counts.orderdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diet_supplements_pivoted.columns = 'order_' + diet_supplements_pivoted.columns\n",
    "diet_supplements_counts.columns = 'order_' + diet_supplements_counts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base9 = base8.merge(diet_supplements_pivoted, how='left', left_on=['masterpatientid','censusdate'], right_on=['order_masterpatientid','order_orderdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base9 = base9.merge(diet_supplements_counts, how='left', left_on=['masterpatientid','censusdate'], right_on=['order_masterpatientid','order_orderdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del base8;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_alerts_system = patient_alerts.loc[patient_alerts.triggereditemtype.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_alerts_therapy = patient_alerts_system.loc[patient_alerts_system.triggereditemtype == 'T']\n",
    "patient_alerts_therapy['createddate'] = patient_alerts_therapy.createddate.dt.date\n",
    "patient_alerts_therapy['alertdescription'] = patient_alerts_therapy.alertdescription.str.split(':').str[0]\n",
    "\n",
    "patient_alerts_therapy['indicator'] = 1\n",
    "patient_alerts_therapy_pivoted = patient_alerts_therapy.loc[:,['masterpatientid', 'createddate', 'alertdescription', 'indicator']].pivot_table(index=['masterpatientid','createddate'], columns='alertdescription', values='indicator', aggfunc=sum).reset_index()\n",
    "patient_alerts_therapy_pivoted['createddate'] = pd.to_datetime(patient_alerts_therapy_pivoted.createddate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allergy_alerts = patient_alerts_system[patient_alerts_system.triggereditemtype == 'A']\n",
    "allergy_alerts['createddate'] = allergy_alerts.createddate.dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allergy_alert_counts = allergy_alerts.groupby(['masterpatientid', 'createddate']).alertdescription.count().reset_index().rename({'alertdescription':'count_indicator_allergy'}, axis=1)\n",
    "allergy_alert_counts['createddate'] = pd.to_datetime(allergy_alert_counts.createddate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispense_alerts = patient_alerts_system[patient_alerts_system.triggereditemtype == 'D']\n",
    "dispense_alerts['createddate'] = dispense_alerts.createddate.dt.date\n",
    "dispense_alert_counts = dispense_alerts.groupby(['masterpatientid', 'createddate']).alertdescription.count().reset_index().rename(columns={'alertdescription':'count_indicator_dispense'})\n",
    "dispense_alert_counts['createddate'] = pd.to_datetime(allergy_alert_counts.createddate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_alerts = patient_alerts_system[patient_alerts_system.triggereditemtype == 'O']\n",
    "order_alerts['createddate'] = order_alerts.createddate.dt.date\n",
    "order_alert_counts = order_alerts.groupby(['masterpatientid', 'createddate']).alertdescription.count().reset_index().rename(columns={'alertdescription':'count_indicator_order'})\n",
    "order_alert_counts['createddate'] = pd.to_datetime(order_alert_counts.createddate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_alerts_therapy_pivoted.columns = 'alert_' + patient_alerts_therapy_pivoted.columns\n",
    "allergy_alert_counts.columns = 'alert_' + allergy_alert_counts.columns\n",
    "dispense_alert_counts.columns = 'alert_' + dispense_alert_counts.columns\n",
    "order_alert_counts.columns = 'alert_' + order_alert_counts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base10 = base9.merge(patient_alerts_therapy_pivoted, how='left', left_on=['masterpatientid', 'censusdate'], right_on=['alert_masterpatientid', 'alert_createddate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base10 = base10.merge(allergy_alert_counts, how='left', left_on=['masterpatientid', 'censusdate'], right_on=['alert_masterpatientid', 'alert_createddate'])\n",
    "base10 = base10.merge(dispense_alert_counts, how='left', left_on=['masterpatientid', 'censusdate'], right_on=['alert_masterpatientid', 'alert_createddate'])\n",
    "base10 = base10.merge(order_alert_counts, how='left', left_on=['masterpatientid', 'censusdate'], right_on=['alert_masterpatientid', 'alert_createddate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del base9;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonsystem_alerts = patient_alerts.loc[patient_alerts.triggereditemtype.isna()]\n",
    "nonsystem_alerts['createddate'] = nonsystem_alerts.createddate.dt.date\n",
    "nonsystem_alerts['indicator'] = 1\n",
    "nonsystem_alerts = nonsystem_alerts.loc[nonsystem_alerts.alertdescription != '-1']\n",
    "alerts_pivoted = nonsystem_alerts.loc[:,['masterpatientid', 'createddate', 'alertdescription', 'indicator']].pivot_table(index=['masterpatientid', 'createddate'], columns=['alertdescription'], values=['indicator'], aggfunc=sum).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alerts_pivoted.columns = clean_multi_columns(alerts_pivoted.columns)\n",
    "alerts_pivoted['createddate'] = pd.to_datetime(alerts_pivoted.createddate)\n",
    "alerts_pivoted.columns = 'alert_' + alerts_pivoted.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base11 = base10.merge(alerts_pivoted, how='left', left_on=['masterpatientid', 'censusdate'], right_on=['alert_masterpatientid', 'alert_createddate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del base10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rehosp = patient_rehosps.merge(patient_census, on=['masterpatientid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_hosp = rehosp[rehosp.dateoftransfer < rehosp.censusdate]\n",
    "last_hosp['count_prior_hosp'] = last_hosp.groupby(['masterpatientid', 'censusdate']).dateoftransfer.cumcount() + 1\n",
    "last_hosp = last_hosp.groupby(['masterpatientid','censusdate']).tail(n=1).loc[:,['masterpatientid', 'censusdate', 'dateoftransfer', 'count_prior_hosp']].rename(columns={'dateoftransfer': 'last_hosp_date'})\n",
    "last_hosp['days_since_last_hosp'] = (last_hosp.censusdate - last_hosp.last_hosp_date).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_hosp = rehosp[rehosp.dateoftransfer > rehosp.censusdate].groupby(['masterpatientid','censusdate']).head(n=1).loc[:,['masterpatientid', 'censusdate', 'dateoftransfer']].rename(columns={'dateoftransfer': 'next_hosp_date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_hosp['target_3_day_hosp'] = (next_hosp.next_hosp_date - next_hosp.censusdate) <= pd.to_timedelta('4 days')\n",
    "next_hosp['target_7_day_hosp'] = (next_hosp.next_hosp_date - next_hosp.censusdate) <= pd.to_timedelta('8 days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_hosp.columns = 'hosp_' + last_hosp.columns\n",
    "next_hosp.columns = 'hosp_' + next_hosp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base12 = base11.merge(last_hosp, how='left', left_on=['masterpatientid','censusdate'], right_on=['hosp_masterpatientid', 'hosp_censusdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base12 = base12.merge(next_hosp, how='left', left_on=['masterpatientid','censusdate'], right_on=['hosp_masterpatientid', 'hosp_censusdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base12 = base12.loc[:,~base12.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_path = Path('/code/data/processed')\n",
    "processed_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base12 = base12.loc[:, base12.columns[~base12.columns.str.contains('_masterpatientid|_facilityid|vtl_date|onsetdate|orderdate|createddate|_x$|_y$')].tolist()]\n",
    "base12 = base12.drop_duplicates(subset=['masterpatientid', 'censusdate'], keep='last')\n",
    "base12.to_parquet(processed_path/'combined.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.read_parquet(processed_path/'combined.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = combined.drop(columns=['hosp_last_hosp_date', 'hosp_next_hosp_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vtl_cols = [col for col in combined.columns if col.startswith('vtl')]\n",
    "dx_cols = [col for col in combined.columns if col.startswith('dx')]\n",
    "med_cols = [col for col in combined.columns if col.startswith('med')]\n",
    "order_cols = [col for col in combined.columns if col.startswith('order')]\n",
    "alert_cols = [col for col in combined.columns if col.startswith('alert')]\n",
    "hosp_cols = [col for col in combined.columns if col.startswith('hosp')]\n",
    "ignore_cols = [col for col in combined.columns if 'target' in col] + ['masterpatientid', 'patientid','censusdate', 'facilityid', 'bedid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_datepart(df, fldname, drop=True, time=False, errors=\"raise\"):\n",
    "    fld = df[fldname]\n",
    "    fld_dtype = fld.dtype\n",
    "    if isinstance(fld_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n",
    "        fld_dtype = np.datetime64\n",
    "\n",
    "    if not np.issubdtype(fld_dtype, np.datetime64):\n",
    "        df[fldname] = fld = pd.to_datetime(fld, infer_datetime_format=True, errors=errors)\n",
    "    attr = ['Year','Month', 'Week', 'Day', 'Dayofweek',\n",
    "            'Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start']\n",
    "    if time: attr = attr + ['Hour', 'Minute', 'Second']\n",
    "    for n in attr: df[fldname + '_' + n] = getattr(fld.dt, n.lower())\n",
    "    if drop: df.drop(fldname, axis=1, inplace=True)\n",
    "        \n",
    "def add_na_indicators(df, ignore_cols):\n",
    "    missings = df.drop(columns=ignore_cols).isna()\n",
    "    missings.columns = 'na_indictator_' + missings.columns\n",
    "    missings_sums = missings.sum()\n",
    "    \n",
    "    return pd.concat([df, missings.loc[:, (missings_sums > 0)]], axis=1)\n",
    "\n",
    "        \n",
    "def proc_vitals(df, vtl_cols):\n",
    "    ffilled = df.groupby('masterpatientid')[vtl_cols].fillna(method='ffill').reset_index()\n",
    "    ffilled['masterpatientid'] = df.masterpatientid\n",
    "    \n",
    "    diff_1_day = ffilled.groupby('masterpatientid')[vtl_cols].diff()\n",
    "    diff_1_day.columns = 'diff_1_day_' + diff_1_day.columns\n",
    "    \n",
    "    diff_7_day = ffilled.groupby('masterpatientid')[vtl_cols].diff(periods=7)\n",
    "    diff_7_day.columns = 'diff_7_day_' + diff_7_day.columns\n",
    "    \n",
    "    rolling_avg_7_day = ffilled.groupby('masterpatientid')[vtl_cols].rolling(7, min_periods=1).mean().reset_index(0, drop=True)\n",
    "    rolling_avg_7_day.columns = 'rol_avg_7_day_' + rolling_avg_7_day.columns\n",
    "    \n",
    "    rolling_avg_14_day = ffilled.groupby('masterpatientid')[vtl_cols].rolling(14, min_periods=1).mean().reset_index(0, drop=True)\n",
    "    rolling_avg_14_day.columns = 'rol_avg_14_day_' + rolling_avg_14_day.columns\n",
    "    \n",
    "    rolling_std_7_day = ffilled.groupby('masterpatientid')[vtl_cols].rolling(7, min_periods=1).std().reset_index(0, drop=True)\n",
    "    rolling_std_7_day.columns = 'rol_std_7_day_' + rolling_std_7_day.columns\n",
    "    \n",
    "    rolling_std_14_day = ffilled.groupby('masterpatientid')[vtl_cols].rolling(14, min_periods=1).std().reset_index(0, drop=True)\n",
    "    rolling_std_14_day.columns = 'rol_std_14_day_' + rolling_std_14_day.columns\n",
    "    \n",
    "    df.loc[:,vtl_cols] = ffilled.loc[:, vtl_cols]\n",
    "    \n",
    "    df = pd.concat([df, diff_1_day, diff_7_day], axis=1) # diffs all indexed the same as original in the same order\n",
    "    \n",
    "    rollings = pd.concat([rolling_avg_7_day, rolling_avg_14_day, rolling_std_7_day, rolling_std_14_day], axis=1)\n",
    "    df = df.merge(rollings, how='left', left_index=True, right_index=True) # rollings were sorted so we explictly join via index\n",
    "    \n",
    "    return df\n",
    "    \n",
    "def proc_dx_meds_alerts_orders(df, dx_cols, med_cols, alert_cols, order_cols):\n",
    "    cols = dx_cols + med_cols + alert_cols + order_cols\n",
    "    filled = df.groupby('masterpatientid')[cols].fillna(0).reset_index()\n",
    "    filled['masterpatientid'] = df.masterpatientid\n",
    "    \n",
    "    cumsum_all_time = filled.groupby('masterpatientid')[cols].cumsum()\n",
    "    cumsum_all_time.columns = 'cumsum_all_' + cumsum_all_time.columns\n",
    "    \n",
    "    cumsum_7_day = filled.groupby('masterpatientid')[cols].rolling(7, min_periods=1).sum().reset_index(0, drop=True)\n",
    "    cumsum_7_day.columns = 'cumsum_7_day_' + cumsum_7_day.columns\n",
    "    \n",
    "    cumsum_15_day = filled.groupby('masterpatientid')[cols].rolling(15, min_periods=1).sum().reset_index(0, drop=True)\n",
    "    cumsum_15_day.columns = 'cumsum_15_day_' + cumsum_15_day.columns\n",
    "    \n",
    "    #cumsum_30_day = filled.groupby('masterpatientid')[cols].rolling(30, min_periods=1).sum().reset_index(0, drop=True)\n",
    "    #cumsum_30_day.columns = 'cumsum_30_day_' + cumsum_30_day.columns\n",
    "    \n",
    "    df = df.drop(columns=cols)\n",
    "    df = pd.concat([df, cumsum_all_time], axis=1) # cumsum is indexed the same as original in the same order\n",
    "    \n",
    "    rollings = pd.concat([cumsum_7_day, cumsum_15_day], axis=1)\n",
    "    df = df.merge(rollings, how='left', left_index=True, right_index=True) # rollings were sorted so we explictly join via index\n",
    "    \n",
    "    return df\n",
    "\n",
    "def proc_demo(df):\n",
    "    df['demo_gender'] = df.gender == 'M'\n",
    "    df['demo_age_in_days'] = (df.censusdate - df.dateofbirth).dt.days\n",
    "    df = pd.concat([df.drop(columns='primarylanguage'), pd.get_dummies(df.primarylanguage, prefix='demo_primarylanguage')], axis=1)\n",
    "    df = pd.concat([df.drop(columns='carelevelcode'), pd.get_dummies(df.carelevelcode, prefix='demo_carelevel')], axis=1)\n",
    "    df = pd.concat([df.drop(columns='race'), pd.get_dummies(df.race, prefix='demo_race')], axis=1)\n",
    "    df = pd.concat([df.drop(columns='education'), pd.get_dummies(df.education, prefix='demo_education')], axis=1)\n",
    "    df = pd.concat([df.drop(columns='religion'), pd.get_dummies(df.religion, prefix='demo_religion')], axis=1)\n",
    "    df = pd.concat([df.drop(columns='facilityid'), pd.get_dummies(df.facilityid, prefix='demo_facility')], axis=1)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = add_na_indicators(combined, ignore_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_datepart(combined, 'censusdate', drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_datepart(combined, 'dateofbirth', drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = proc_vitals(combined, vtl_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = proc_dx_meds_alerts_orders(combined, dx_cols, med_cols, alert_cols, order_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.to_parquet(processed_path/'after_vtl_and_cumsums.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.read_parquet(processed_path/'after_vtl_and_cumsums.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = proc_demo(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = combined.drop_duplicates(subset=['masterpatientid', 'censusdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.to_parquet(processed_path/'final_processed.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_path = Path('/code/data/processed')\n",
    "final = pd.read_parquet(processed_path/'final_processed.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['bedid', 'beddescription', 'roomratetypedescription', 'payercode', 'patientid', \n",
    "             'gender', 'dateofbirth', 'citizenship', 'state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual check to make sure we're not including any columns that could leak data\n",
    "with open('/code/columns.txt','w') as f:\n",
    "    for col in final.columns:\n",
    "        f.write(col + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_day = final.loc[:,'censusdate'].iloc[round(final.shape[0] * (1-.2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = final.loc[final.censusdate <= split_day]\n",
    "valid = final.loc[final.censusdate > split_day]\n",
    "\n",
    "train.to_pickle(processed_path/'train.pickle')\n",
    "valid.to_pickle(processed_path/'valid.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_path = Path('/code/data/processed')\n",
    "train = pd.read_pickle(processed_path/'train.pickle')\n",
    "valid = pd.read_pickle(processed_path/'valid.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = train['cumsum_all_dx_Diseases of the respiratory system - Chronic obstructive pulmonary disease and bronchiectasis [127.]'] > 0\n",
    "valid_mask = valid['cumsum_all_dx_Diseases of the respiratory system - Chronic obstructive pulmonary disease and bronchiectasis [127.]'] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{len(train[train_mask].masterpatientid.unique())} patients out of {len(train.masterpatientid.unique())} have COPD associated with them')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_patients = train[train_mask].masterpatientid.unique()\n",
    "valid_patients = valid[valid_mask].masterpatientid.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train.masterpatientid.isin(train_patients)]\n",
    "valid = valid[valid.masterpatientid.isin(valid_patients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_na_train(df):\n",
    "    has_na = df.isna().sum() > 0\n",
    "    d = df.loc[:, has_na].median()\n",
    "    df = df.fillna(d)\n",
    "    \n",
    "    return df, d\n",
    "\n",
    "def fill_na_valid(df, na_filler):\n",
    "    return df.fillna(na_filler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in any remaining na's - now that we're not forwardfilling past info it's not correct to use a global imputation\n",
    "# hence we impute on the train and apply to the valid\n",
    "train, na_filler = fill_na_train(train)\n",
    "valid = fill_na_valid(valid, na_filler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_pickle(processed_path/'train_filled.pickle')\n",
    "valid.to_pickle(processed_path/'valid_filled.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_path = Path('/code/data/processed')\n",
    "train = pd.read_pickle(processed_path/'train_filled.pickle')\n",
    "valid = pd.read_pickle(processed_path/'valid_filled.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.censusdate.min(), train.censusdate.max(), train.hosp_target_7_day_hosp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid.censusdate.min(), valid.censusdate.max(), valid.hosp_target_7_day_hosp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(df):\n",
    "    drop_cols = ['censusdate', 'masterpatientid']\n",
    "    drop_cols = drop_cols + [col for col in df.columns if 'target' in col]\n",
    "    \n",
    "    y = df.hosp_target_7_day_hosp.astype('float32').values\n",
    "    x = df.drop(columns=drop_cols).reset_index(drop=True).astype('float32')\n",
    "    idens = df.loc[:,['masterpatientid','censusdate']]\n",
    "    \n",
    "    return x, y, idens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, train_idens = prep(train)\n",
    "valid_x, valid_y, valid_idens = prep(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle;\n",
    "with open('/code/data/processed/train_x.pickle','wb') as f: pickle.dump(train_x, f, protocol=4)\n",
    "with open('/code/data/processed/train_y.pickle','wb') as f: pickle.dump(train_y, f, protocol=4)\n",
    "with open('/code/data/processed/train_idens.pickle','wb') as f: pickle.dump(train_idens, f, protocol=4)\n",
    "with open('/code/data/processed/valid_x.pickle','wb') as f: pickle.dump(valid_x, f, protocol=4)\n",
    "with open('/code/data/processed/valid_y.pickle','wb') as f: pickle.dump(valid_y, f, protocol=4)\n",
    "with open('/code/data/processed/valid_idens.pickle','wb') as f: pickle.dump(valid_idens, f, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle;\n",
    "with open('/code/data/processed/copd_train_x.pickle','rb') as f: train_x = pickle.load(f)\n",
    "with open('/code/data/processed/copd_train_y.pickle','rb') as f: train_y = pickle.load(f)\n",
    "with open('/code/data/processed/copd_train_idens.pickle','rb') as f: train_idens = pickle.load(f)\n",
    "with open('/code/data/processed/copd_valid_x.pickle','rb') as f: valid_x = pickle.load(f)\n",
    "with open('/code/data/processed/copd_valid_y.pickle','rb') as f: valid_y =pickle.load(f)\n",
    "with open('/code/data/processed/copd_valid_idens.pickle','rb') as f: valid_idens =pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators':[1000],\n",
    "    'feat_select_threshold': ['32*median', '40*median', '48*median'],\n",
    "    'max_features': ['auto', .1, .2], \n",
    "    'min_samples_leaf': [100, 200, 300], \n",
    "    'class_weight': [None],\n",
    "    'all_data': [False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment('copd_target_hosp_7_day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for config in ParameterGrid(param_grid):\n",
    "    print(f'Trying hyperparamters: {config}')\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        feat_est = forest.RandomForestClassifier(\n",
    "            n_estimators=config['n_estimators'],\n",
    "            max_features=config['max_features'],\n",
    "            min_samples_leaf=config['min_samples_leaf'],\n",
    "            class_weight=config['class_weight'],\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        feat_selector = SelectFromModel(feat_est, threshold=config['feat_select_threshold'])\n",
    "        train_x_new = feat_selector.fit_transform(train_x, train_y)\n",
    "\n",
    "        clf = forest.RandomForestClassifier(\n",
    "            n_estimators=config['n_estimators'],\n",
    "            max_features=config['max_features'],\n",
    "            min_samples_leaf=config['min_samples_leaf'],\n",
    "            class_weight=config['class_weight'],\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        clf.fit(train_x_new, train_y)\n",
    "\n",
    "        valid_x_new = feat_selector.transform(valid_x)\n",
    "\n",
    "        train_preds = clf.predict_proba(train_x_new)\n",
    "        valid_preds = clf.predict_proba(valid_x_new)\n",
    "\n",
    "        for param in config:\n",
    "            log_param(param, config[param])\n",
    "\n",
    "        #log_metric('train_aucroc', roc_auc_score(train_y, [pred[1] for pred in train_preds]))\n",
    "        #log_metric('train_ap', average_precision_score(train_y, [pred[1] for pred in train_preds]))\n",
    "        log_metric('valid_aucroc', roc_auc_score(valid_y, [pred[1] for pred in valid_preds]))\n",
    "        log_metric('valid_ap', average_precision_score(valid_y, [pred[1] for pred in valid_preds]))\n",
    "\n",
    "        log_model(feat_selector, 'feat_selector')\n",
    "        log_model(clf, \"model\")\n",
    "\n",
    "        feature_selected_features = pd.DataFrame(zip(train_x.columns[feat_selector.get_support()], clf.feature_importances_), columns=['feature', 'rf_importance']).sort_values('rf_importance', ascending=False)\n",
    "        feature_selected_features.to_csv('./feature_selected_features.csv', index=False)\n",
    "        log_artifact('./feature_selected_features.csv')\n",
    "\n",
    "        input_features = pd.DataFrame(train_x.columns, columns=['feature'])\n",
    "        input_features.to_csv('./input_features.csv', index=False)\n",
    "        log_artifact('./input_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_est = forest.RandomForestClassifier(\n",
    "    n_estimators=1000,\n",
    "    max_features='auto',\n",
    "    min_samples_leaf=200,\n",
    "    class_weight=None,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "feat_selector = SelectFromModel(feat_est, threshold='32*median')\n",
    "train_x_new = feat_selector.fit_transform(train_x, train_y)\n",
    "\n",
    "clf = forest.RandomForestClassifier(\n",
    "    n_estimators=1000,\n",
    "    max_features='auto',\n",
    "    min_samples_leaf=200,\n",
    "    class_weight=None,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "clf.fit(train_x_new, train_y)\n",
    "\n",
    "valid_x_new = feat_selector.transform(valid_x)\n",
    "valid_preds = clf.predict_proba(valid_x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision_score(valid_y, [pred[1] for pred in valid_preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x_shap = pd.concat([valid_x.loc[:, feat_selector.get_support()].reset_index(drop=True), valid_idens.reset_index(drop=True)], axis=1)\n",
    "valid_x_shap['preds'] = [pred[1] for pred in valid_preds]\n",
    "valid_x_shap['target'] = valid_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x_shap = valid_x_shap[valid_x_shap.censusdate == pd.to_datetime('2019-02-20')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_valid = valid_x_shap.sort_values(by='preds', ascending=False)\n",
    "sorted_valid_dr = sorted_valid.drop(columns=['preds', 'masterpatientid', 'censusdate'])\n",
    "idens = sorted_valid.loc[:, ['masterpatientid', 'censusdate', 'preds', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = sorted_valid_dr.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value[1], shap_values[1][0], tt.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "\n",
    "for i in range(0,10):\n",
    "    shaps = pd.DataFrame({'feature_name':tt.columns, 'shap_value': shap_values[1][i], 'feature_value': tt.iloc[i]}).sort_values(by='shap_value', ascending=False)\n",
    "    shaps = shaps.head(n=10)\n",
    "    shaps['masterpatientid'] = hash(str(idens.iloc[i].masterpatientid))\n",
    "    shaps['censusdate'] = idens.iloc[i].censusdate\n",
    "    shaps['prediction'] = idens.iloc[i].preds\n",
    "    shaps['rehosped'] = idens.iloc[i].target\n",
    "    out.append(shaps)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(out).to_csv('/code/data/copd_model_2019-02-20.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'feature_name':tt.columns, 'shap_value': shap_values[1][0], 'feature_value': tt.iloc[0]}).sort_values(by='shap_value', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = pd.read_csv('/code/mlruns/3/cb90d2e7f30f4aacabedd14c89c0f536/artifacts/input_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vtl_median_BP - Systolic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vtl_median_Blood Sugar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vtl_median_Height</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vtl_median_O2 sats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vtl_median_Pain Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vtl_median_Pulse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vtl_median_Respiration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vtl_median_Temperature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vtl_median_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vtl_std_BP - Systolic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vtl_std_Blood Sugar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>vtl_std_Height</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vtl_std_O2 sats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vtl_std_Pain Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>vtl_std_Pulse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>vtl_std_Respiration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>vtl_std_Temperature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>vtl_std_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>vtl_max_BP - Systolic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>vtl_max_Blood Sugar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>vtl_max_Height</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>vtl_max_O2 sats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>vtl_max_Pain Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>vtl_max_Pulse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>vtl_max_Respiration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>vtl_max_Temperature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>vtl_max_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>vtl_min_BP - Systolic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>vtl_min_Blood Sugar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>vtl_min_Height</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3163</th>\n",
       "      <td>demo_religion_NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3164</th>\n",
       "      <td>demo_religion_Pentecostal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3165</th>\n",
       "      <td>demo_religion_Presbyterian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3166</th>\n",
       "      <td>demo_religion_Protestant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3167</th>\n",
       "      <td>demo_religion_Seventh-day Adventist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3168</th>\n",
       "      <td>demo_religion_Sikh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3169</th>\n",
       "      <td>demo_religion_United</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3170</th>\n",
       "      <td>demo_religion_Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3171</th>\n",
       "      <td>demo_religion_Wesleyan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3172</th>\n",
       "      <td>demo_facility_1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3173</th>\n",
       "      <td>demo_facility_3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3174</th>\n",
       "      <td>demo_facility_4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3175</th>\n",
       "      <td>demo_facility_5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3176</th>\n",
       "      <td>demo_facility_6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3177</th>\n",
       "      <td>demo_facility_7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3178</th>\n",
       "      <td>demo_facility_8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3179</th>\n",
       "      <td>demo_facility_9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3180</th>\n",
       "      <td>demo_facility_10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3181</th>\n",
       "      <td>demo_facility_11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3182</th>\n",
       "      <td>demo_facility_12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3183</th>\n",
       "      <td>demo_facility_13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3184</th>\n",
       "      <td>demo_facility_14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3185</th>\n",
       "      <td>demo_facility_15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186</th>\n",
       "      <td>demo_facility_16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3187</th>\n",
       "      <td>demo_facility_17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3188</th>\n",
       "      <td>demo_facility_18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3189</th>\n",
       "      <td>demo_facility_19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3190</th>\n",
       "      <td>demo_facility_20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3191</th>\n",
       "      <td>demo_facility_21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3192</th>\n",
       "      <td>demo_facility_26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3193 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  feature\n",
       "0                vtl_median_BP - Systolic\n",
       "1                  vtl_median_Blood Sugar\n",
       "2                       vtl_median_Height\n",
       "3                      vtl_median_O2 sats\n",
       "4                   vtl_median_Pain Level\n",
       "5                        vtl_median_Pulse\n",
       "6                  vtl_median_Respiration\n",
       "7                  vtl_median_Temperature\n",
       "8                       vtl_median_Weight\n",
       "9                   vtl_std_BP - Systolic\n",
       "10                    vtl_std_Blood Sugar\n",
       "11                         vtl_std_Height\n",
       "12                        vtl_std_O2 sats\n",
       "13                     vtl_std_Pain Level\n",
       "14                          vtl_std_Pulse\n",
       "15                    vtl_std_Respiration\n",
       "16                    vtl_std_Temperature\n",
       "17                         vtl_std_Weight\n",
       "18                  vtl_max_BP - Systolic\n",
       "19                    vtl_max_Blood Sugar\n",
       "20                         vtl_max_Height\n",
       "21                        vtl_max_O2 sats\n",
       "22                     vtl_max_Pain Level\n",
       "23                          vtl_max_Pulse\n",
       "24                    vtl_max_Respiration\n",
       "25                    vtl_max_Temperature\n",
       "26                         vtl_max_Weight\n",
       "27                  vtl_min_BP - Systolic\n",
       "28                    vtl_min_Blood Sugar\n",
       "29                         vtl_min_Height\n",
       "...                                   ...\n",
       "3163                   demo_religion_NONE\n",
       "3164            demo_religion_Pentecostal\n",
       "3165           demo_religion_Presbyterian\n",
       "3166             demo_religion_Protestant\n",
       "3167  demo_religion_Seventh-day Adventist\n",
       "3168                   demo_religion_Sikh\n",
       "3169                 demo_religion_United\n",
       "3170                demo_religion_Unknown\n",
       "3171               demo_religion_Wesleyan\n",
       "3172                    demo_facility_1.0\n",
       "3173                    demo_facility_3.0\n",
       "3174                    demo_facility_4.0\n",
       "3175                    demo_facility_5.0\n",
       "3176                    demo_facility_6.0\n",
       "3177                    demo_facility_7.0\n",
       "3178                    demo_facility_8.0\n",
       "3179                    demo_facility_9.0\n",
       "3180                   demo_facility_10.0\n",
       "3181                   demo_facility_11.0\n",
       "3182                   demo_facility_12.0\n",
       "3183                   demo_facility_13.0\n",
       "3184                   demo_facility_14.0\n",
       "3185                   demo_facility_15.0\n",
       "3186                   demo_facility_16.0\n",
       "3187                   demo_facility_17.0\n",
       "3188                   demo_facility_18.0\n",
       "3189                   demo_facility_19.0\n",
       "3190                   demo_facility_20.0\n",
       "3191                   demo_facility_21.0\n",
       "3192                   demo_facility_26.0\n",
       "\n",
       "[3193 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
